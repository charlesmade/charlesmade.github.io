{"meta":{"title":"Zeco's blog","subtitle":null,"description":null,"author":"Zeco","url":"http://zeco.oschina.io"},"pages":[{"title":"Categories","date":"un11fin11","updated":"un11fin11","comments":true,"path":"categories/index.html","permalink":"http://zeco.oschina.io/categories/index.html","excerpt":"","text":""},{"title":"关于作者","date":"un00fin00","updated":"un00fin00","comments":true,"path":"about/index.html","permalink":"http://zeco.oschina.io/about/index.html","excerpt":"","text":"半路出家的和尚，是不点戒疤的 张一刀是也"},{"title":"标签云","date":"un00fin00","updated":"un00fin00","comments":true,"path":"tags/index.html","permalink":"http://zeco.oschina.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"LinuxCon引发的思考","slug":"futrue_road","date":"un33fin33","updated":"un33fin33","comments":true,"path":"2017/06/28/futrue_road/","link":"","permalink":"http://zeco.oschina.io/2017/06/28/futrue_road/","excerpt":"2017年的夏天，LinuxCon第一次在中国召开，一年之前，我对这个消息一点反应也没有，现在却突兀的觉得有些触动，似乎某些不起眼的东西就发生在你身边，这世界上没有谁能知道这对未来代表了什么","text":"2017年的夏天，LinuxCon第一次在中国召开，一年之前，我对这个消息一点反应也没有，现在却突兀的觉得有些触动，似乎某些不起眼的东西就发生在你身边，这世界上没有谁能知道这对未来代表了什么，我不知道，你也不知道，但世间的事总是这样，不是等你准备好了再发生，而是有着它自己的规律，就那么生长着，盛放着，爆发着，然后死亡。 闲扯了一堆没头没脑的话，就像我近来混沌的头脑，里面填了一些东西，反倒不如当初清醒，不知道自己需要什么了。 然而，今天突然看到linus在和Dirk Hohndel的炉边谈话里的这么一句话 For me, I was always self-motivated and knew what I wanted to do. I was never told what I should look at doing. I’m not sure my example is the right thing for people to follow. There are a ton of open source projects and, if you are a beginning programmer, find something you’re interested in that you can follow for more than just a few weeks. Get to know the code so well that you get to the point where you are an expert on a code piece. It doesn’t need to be the whole project. No one is an expert on the whole kernel, but you can know an area well. If you can be part of a community and set up patches, it’s not just about the coding, but about the social aspect of open source. You make connections and improve yourself as a programmer. You are basically showing off – I made these improvements, I’m capable of going far in my community or job. You’ll have to spend a certain amount of time to learn a project, but there’s a huge upside – not just from a career aspect, but having an amazing project in your life. 对于其中it’s not just about the coding，you make connections 这两句话话，感触尤深。 毫无波澜的工作生活往往让我们忘记一些东西，有些时候我们通过游戏，狂欢来消磨忘记它们，但这世界上最稳固的东西就是我们每天都要面对的日出日落，不论怎么逃避，他就在那里等着你回去，等着你去面对他。 我也模糊的明晰了自己所需要的东西，我不需要在每一个方面做得完美，但需要在某一个方面，做到令自己自豪的成绩，最后，一句话送给自己和看到这篇文章的你，the day and night, not only for small life,but for a gaint soul.","categories":[{"name":"闲扯","slug":"闲扯","permalink":"http://zeco.oschina.io/categories/闲扯/"},{"name":"职业思考","slug":"闲扯/职业思考","permalink":"http://zeco.oschina.io/categories/闲扯/职业思考/"}],"tags":[{"name":"about futrue","slug":"about-futrue","permalink":"http://zeco.oschina.io/tagcloud/about-futrue/"}]},{"title":"秒杀系统架构分析与实战[转]","slug":"quene","date":"un00fin00","updated":"un00fin00","comments":true,"path":"2017/05/14/quene/","link":"","permalink":"http://zeco.oschina.io/2017/05/14/quene/","excerpt":"秒杀业务分析 正常电子商务流程 （1）查询商品；（2）创建订单；（3）扣减库存；（4）更新订单；（5）付款；（6）卖家发货 秒杀业务的特性 （1）低廉价格；（2）大幅推广；（3）瞬时售空；（4）一般是定时上架；（5）时间短、瞬时并发量高； 秒杀技术挑战假设某网站秒杀活动只推出一件商品，预计会吸引1万人参加活动，也就说最大并发请求数是10000，秒杀系统需要面对的技术挑战有：","text":"秒杀业务分析 正常电子商务流程 （1）查询商品；（2）创建订单；（3）扣减库存；（4）更新订单；（5）付款；（6）卖家发货 秒杀业务的特性 （1）低廉价格；（2）大幅推广；（3）瞬时售空；（4）一般是定时上架；（5）时间短、瞬时并发量高； 秒杀技术挑战假设某网站秒杀活动只推出一件商品，预计会吸引1万人参加活动，也就说最大并发请求数是10000，秒杀系统需要面对的技术挑战有： 对现有网站业务造成冲击秒杀活动只是网站营销的一个附加活动，这个活动具有时间短，并发访问量大的特点，如果和网站原有应用部署在一起，必然会对现有业务造成冲击，稍有不慎可能导致整个网站瘫痪。 解决方案：将秒杀系统独立部署，甚至使用独立域名，使其与网站完全隔离。 高并发下的应用、数据库负载用户在秒杀开始前，通过不停刷新浏览器页面以保证不会错过秒杀，这些请求如果按照一般的网站应用架构，访问应用服务器、连接数据库，会对应用服务器和数据库服务器造成负载压力。 解决方案：重新设计秒杀商品页面，不使用网站原来的商品详细页面，页面内容静态化，用户请求不需要经过应用服务。 突然增加的网络及服务器带宽假设商品页面大小200K（主要是商品图片大小），那么需要的网络和服务器带宽是2G（200K×10000），这些网络带宽是因为秒杀活动新增的，超过网站平时使用的带宽。 解决方案：因为秒杀新增的网络带宽，必须和运营商重新购买或者租借。为了减轻网站服务器的压力，需要将秒杀商品页面缓存在CDN，同样需要和CDN服务商临时租借新增的出口带宽。 直接下单秒杀的游戏规则是到了秒杀才能开始对商品下单购买，在此时间点之前，只能浏览商品信息，不能下单。而下单页面也是一个普通的URL，如果得到这个URL，不用等到秒杀开始就可以下单了。 解决方案：为了避免用户直接访问下单页面URL，需要将改URL动态化，即使秒杀系统的开发者也无法在秒杀开始前访问下单页面的URL。办法是在下单页面URL加入由服务器端生成的随机数作为参数，在秒杀开始的时候才能得到。 如何控制秒杀商品页面购买按钮的点亮购买按钮只有在秒杀开始的时候才能点亮，在此之前是灰色的。如果该页面是动态生成的，当然可以在服务器端构造响应页面输出，控制该按钮是灰色还 是点亮，但是为了减轻服务器端负载压力，更好地利用CDN、反向代理等性能优化手段，该页面被设计为静态页面，缓存在CDN、反向代理服务器上，甚至用户浏览器上。秒杀开始时，用户刷新页面，请求根本不会到达应用服务器。 解决方案：使用JavaScript脚本控制，在秒杀商品静态页面中加入一个JavaScript文件引用，该JavaScript文件中包含 秒杀开始标志为否；当秒杀开始的时候生成一个新的JavaScript文件（文件名保持不变，只是内容不一样），更新秒杀开始标志为是，加入下单页面的URL及随机数参数（这个随机数只会产生一个，即所有人看到的URL都是同一个，服务器端可以用redis这种分布式缓存服务器来保存随机数），并被用户浏览器加载，控制秒杀商品页面的展示。这个JavaScript文件的加载可以加上随机版本号（例如xx.js?v=32353823），这样就不会被浏览器、CDN和反向代理服务器缓存。 这个JavaScript文件非常小，即使每次浏览器刷新都访问JavaScript文件服务器也不会对服务器集群和网络带宽造成太大压力。 如何只允许第一个提交的订单被发送到订单子系统由于最终能够成功秒杀到商品的用户只有一个，因此需要在用户提交订单时，检查是否已经有订单提交。如果已经有订单提交成功，则需要更新 JavaScript文件，更新秒杀开始标志为否，购买按钮变灰。事实上，由于最终能够成功提交订单的用户只有一个，为了减轻下单页面服务器的负载压力， 可以控制进入下单页面的入口，只有少数用户能进入下单页面，其他用户直接进入秒杀结束页面。 解决方案：假设下单服务器集群有10台服务器，每台服务器只接受最多10个下单请求。在还没有人提交订单成功之前，如果一台服务器已经有十单了，而有的一单都没处理，可能出现的用户体验不佳的场景是用户第一次点击购买按钮进入已结束页面，再刷新一下页面，有可能被一单都没有处理的服务器处理，进入了填写订单的页面，可以考虑通过cookie的方式来应对，符合一致性原则。当然可以采用最少连接的负载均衡算法，出现上述情况的概率大大降低。 如何进行下单前置检查下单服务器检查本机已处理的下单请求数目：如果超过10条，直接返回已结束页面给用户； 如果未超过10条，则用户可进入填写订单及确认页面； 检查全局已提交订单数目：已超过秒杀商品总数，返回已结束页面给用户； 未超过秒杀商品总数，提交到子订单系统； 秒杀一般是定时上架该功能实现方式很多。不过目前比较好的方式是：提前设定好商品的上架时间，用户可以在前台看到该商品，但是无法点击“立即购买”的按钮。但是需要考虑的是，有人可以绕过前端的限制，直接通过URL的方式发起购买，这就需要在前台商品页面，以及bug页面到后端的数据库，都要进行时钟同步。越在后端控制，安全性越高。 定时秒杀的话，就要避免卖家在秒杀前对商品做编辑带来的不可预期的影响。这种特殊的变更需要多方面评估。一般禁止编辑，如需变更，可以走数据订正多的流程。 减库存的操作有两种选择，一种是拍下减库存 另外一种是付款减库存；目前采用的“拍下减库存”的方式，拍下就是一瞬间的事，对用户体验会好些。 库存会带来“超卖”的问题：售出数量多于库存数量由于库存并发更新的问题，导致在实际库存已经不足的情况下，库存依然在减，导致卖家的商品卖得件数超过秒杀的预期。方案：采用乐观锁 123update auction_auctions setquantity = #inQuantity#where auction_id = #itemId# and quantity = #dbQuantity# 还有一种方式，会更好些，叫做尝试扣减库存，扣减库存成功才会进行下单逻辑： 123update auction_auctions set quantity = quantity-#count# where auction_id = #itemId# and quantity &gt;= #count# 秒杀器的应对秒杀器一般下单个购买及其迅速，根据购买记录可以甄别出一部分。可以通过校验码达到一定的方法，这就要求校验码足够安全，不被破解，采用的方式有：秒杀专用验证码，电视公布验证码，秒杀答题。 秒杀架构原则尽量将请求拦截在系统上游传统秒杀系统之所以挂，请求都压倒了后端数据层，数据读写锁冲突严重，并发高响应慢，几乎所有请求都超时，流量虽大，下单成功的有效流量甚小【一趟火车其实只有2000张票，200w个人来买，基本没有人能买成功，请求有效率为0】。 读多写少的常用多使用缓存这是一个典型的读多写少的应用场景【一趟火车其实只有2000张票，200w个人来买，最多2000个人下单成功，其他人都是查询库存，写比例只有0.1%，读比例占99.9%】，非常适合使用缓存。 秒杀架构设计秒杀系统为秒杀而设计，不同于一般的网购行为，参与秒杀活动的用户更关心的是如何能快速刷新商品页面，在秒杀开始的时候抢先进入下单页面，而不是商品详情等用户体验细节，因此秒杀系统的页面设计应尽可能简单。 商品页面中的购买按钮只有在秒杀活动开始的时候才变亮，在此之前及秒杀商品卖出后，该按钮都是灰色的，不可以点击。 下单表单也尽可能简单，购买数量只能是一个且不可以修改，送货地址和付款方式都使用用户默认设置，没有默认也可以不填，允许等订单提交后修改；只有第一个提交的订单发送给网站的订单子系统，其余用户提交订单后只能看到秒杀结束页面。 要做一个这样的秒杀系统，业务会分为两个阶段，第一个阶段是秒杀开始前某个时间到秒杀开始， 这个阶段可以称之为准备阶段，用户在准备阶段等待秒杀； 第二个阶段就是秒杀开始到所有参与秒杀的用户获得秒杀结果， 这个就称为秒杀阶段吧。 前端层设计首先要有一个展示秒杀商品的页面， 在这个页面上做一个秒杀活动开始的倒计时， 在准备阶段内用户会陆续打开这个秒杀的页面， 并且可能不停的刷新页面。这里需要考虑两个问题： 第一个是秒杀页面的展示我们知道一个html页面还是比较大的，即使做了压缩，http头和内容的大小也可能高达数十K，加上其他的css， js，图片等资源，如果同时有几千万人参与一个商品的抢购，一般机房带宽也就只有1G~10G，网络带宽就极有可能成为瓶颈，所以这个页面上各类静态资源首先应分开存放，然后放到cdn节点上分散压力，由于CDN节点遍布全国各地，能缓冲掉绝大部分的压力，而且还比机房带宽便宜~ 第二个是倒计时出于性能原因这个一般由js调用客户端本地时间，就有可能出现客户端时钟与服务器时钟不一致，另外服务器之间也是有可能出现时钟不一致。客户端与服务器时钟不一致可以采用客户端定时和服务器同步时间，这里考虑一下性能问题，用于同步时间的接口由于不涉及到后端逻辑，只需要将当前web服务器的时间发送给客户端就可以了，因此速度很快，就我以前测试的结果来看，一台标准的web服务器2W+QPS不会有问题，如果100W人同时刷，100W QPS也只需要50台web，一台硬件LB就可以了~，并且web服务器群是可以很容易的横向扩展的(LB+DNS轮询)，这个接口可以只返回一小段json格式的数据，而且可以优化一下减少不必要cookie和其他http头的信息，所以数据量不会很大，一般来说网络不会成为瓶颈，即使成为瓶颈也可以考虑多机房专线连通，加智能DNS的解决方案；web服务器之间时间不同步可以采用统一时间服务器的方式，比如每隔1分钟所有参与秒杀活动的web服务器就与时间服务器做一次时间同步。 3.浏览器层请求拦截（1）产品层面，用户点击“查询”或者“购票”后，按钮置灰，禁止用户重复提交请求;（2）JS层面，限制用户在x秒之内只能提交一次请求; 站点层设计前端层的请求拦截，只能拦住小白用户（不过这是99%的用户哟），高端的程序员根本不吃这一套，写个for循环，直接调用你后端的http请求，怎么整？ （1）同一个uid，限制访问频度，做页面缓存，x秒内到达站点层的请求，均返回同一页面 （2）同一个item的查询，例如手机车次，做页面缓存，x秒内到达站点层的请求，均返回同一页面 如此限流，又有99%的流量会被拦截在站点层。 服务层设计站点层的请求拦截，只能拦住普通程序员，高级黑客，假设他控制了10w台肉鸡（并且假设买票不需要实名认证），这下uid的限制不行了吧？怎么整？ （1）大哥，我是服务层，我清楚的知道小米只有1万部手机，我清楚的知道一列火车只有2000张车票，我透10w个请求去数据库有什么意义呢？对于写请求，做请求队列，每次只透过有限的写请求去数据层，如果均成功再放下一批，如果库存不够则队列里的写请求全部返回“已售完”； （2）对于读请求，还用说么？cache来抗，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题的； 如此限流，只有非常少的写请求，和非常少的读缓存mis的请求会透到数据层去，又有99.9%的请求被拦住了。 用户请求分发模块：使用Nginx或Apache将用户的请求分发到不同的机器上。 用户请求预处理模块：判断商品是不是还有剩余来决定是不是要处理该请求。 用户请求处理模块：把通过预处理的请求封装成事务提交给数据库，并返回是否成功。 数据库接口模块：该模块是数据库的唯一接口，负责与数据库交互，提供RPC接口供查询是否秒杀结束、剩余数量等信息。 用户请求预处理模块经过HTTP服务器的分发后，单个服务器的负载相对低了一些，但总量依然可能很大，如果后台商品已经被秒杀完毕，那么直接给后来的请求返回秒杀失败即可，不必再进一步发送事务了，示例代码可以如下所示： 123456789101112131415161718192021222324252627282930313233package seckill;import org.apache.http.HttpRequest;/*** 预处理阶段，把不必要的请求直接驳回，必要的请求添加到队列中进入下一阶段.*/public class PreProcessor &#123; // 商品是否还有剩余 private static boolean reminds = true; private static void forbidden() &#123; // Do something. &#125; public static boolean checkReminds() &#123; if (reminds) &#123; // 远程检测是否还有剩余，该RPC接口应由数据库服务器提供，不必完全严格检查. if (!RPC.checkReminds()) &#123; reminds = false; &#125; &#125; return reminds; &#125; /** * 每一个HTTP请求都要经过该预处理. */ public static void preProcess(HttpRequest request) &#123; if (checkReminds()) &#123; // 一个并发的队列 RequestQueue.queue.add(request); &#125; else &#123; // 如果已经没有商品了，则直接驳回请求即可. forbidden(); &#125; &#125;&#125; 并发队列的选择Java的并发包提供了三个常用的并发队列实现，分别是：ConcurrentLinkedQueue 、 LinkedBlockingQueue 和 ArrayBlockingQueue。 ArrayBlockingQueue是初始容量固定的阻塞队列，我们可以用来作为数据库模块成功竞拍的队列，比如有10个商品，那么我们就设定一个10大小的数组队列。 ConcurrentLinkedQueue使用的是CAS原语无锁队列实现，是一个异步队列，入队的速度很快，出队进行了加锁，性能稍慢。 LinkedBlockingQueue也是阻塞的队列，入队和出队都用了加锁，当队空的时候线程会暂时阻塞。 由于我们的系统入队需求要远大于出队需求，一般不会出现队空的情况，所以我们可以选择ConcurrentLinkedQueue来作为我们的请求队列实现： 1234567package seckill;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ConcurrentLinkedQueue;import org.apache.http.HttpRequest;public class RequestQueue &#123; public static ConcurrentLinkedQueue&lt;HttpRequest&gt; queue = new ConcurrentLinkedQueue&lt;HttpRequest&gt;();&#125; 用户请求模块123456789101112131415161718192021package seckill;import org.apache.http.HttpRequest;public class Processor &#123; /** * 发送秒杀事务到数据库队列. */ public static void kill(BidInfo info) &#123; DB.bids.add(info); &#125; public static void process() &#123; BidInfo info = new BidInfo(RequestQueue.queue.poll()); if (info != null) &#123; kill(info); &#125; &#125;&#125;class BidInfo &#123; BidInfo(HttpRequest request) &#123; // Do something. &#125;&#125; 数据库模块数据库主要是使用一个ArrayBlockingQueue来暂存有可能成功的用户请求。 1234567891011121314151617181920212223package seckill;import java.util.concurrent.ArrayBlockingQueue;/*** DB应该是数据库的唯一接口.*/public class DB &#123; public static int count = 10; public static ArrayBlockingQueue&lt;BidInfo&gt; bids = new ArrayBlockingQueue&lt;BidInfo&gt;(10); public static boolean checkReminds() &#123; // TODO return true; &#125; // 单线程操作 public static void bid() &#123; BidInfo info = bids.poll(); while (count-- &gt; 0) &#123; // insert into table Bids values(item_id, user_id, bid_date, other) // select count(id) from Bids where item_id = ? // 如果数据库商品数量大约总数，则标志秒杀已完成，设置标志位reminds = false. info = bids.poll(); &#125; &#125;&#125; 数据库设计基本概念概念一“单库” 概念二“分片” 分片解决的是“数据量太大”的问题，也就是通常说的“水平切分”。 一旦引入分片，势必有“数据路由”的概念，哪个数据访问哪个库。路由规则通常有3种方法： 范围：range优点：简单，容易扩展缺点：各库压力不均（新号段更活跃） 哈希：hash 【大部分互联网公司采用的方案二：哈希分库，哈希路由】优点：简单，数据均衡，负载均匀缺点：迁移麻烦（2库扩3库数据要迁移） 3.路由服务：router-config-server优点：灵活性强，业务与路由算法解耦缺点：每次访问数据库前多一次查询 概念三“分组” 分组解决“可用性”问题，分组通常通过主从复制的方式实现。 互联网公司数据库实际软件架构是：又分片，又分组（如下图） 设计思路数据库软件架构师平时设计些什么东西呢？至少要考虑以下四点： 如何保证数据可用性； 如何提高数据库读性能（大部分应用读多写少，读会先成为瓶颈）； 如何保证一致性； 如何提高扩展性； 如何保证数据的可用性？解决可用性问题的思路是=&gt;冗余 如何保证站点的可用性？复制站点，冗余站点 如何保证服务的可用性？复制服务，冗余服务 如何保证数据的可用性？复制数据，冗余数据 数据的冗余，会带来一个副作用=&gt;引发一致性问题（先不说一致性问题，先说可用性）。 如何保证数据库“读”高可用？冗余读库 冗余读库带来的副作用？读写有延时，可能不一致 上面这个图是很多互联网公司mysql的架构，写仍然是单点，不能保证写高可用。 如何保证数据库“写”高可用？冗余写库 采用双主互备的方式，可以冗余写库带来的副作用？双写同步，数据可能冲突（例如“自增id”同步冲突）,如何解决同步冲突，有两种常见解决方案： 两个写库使用不同的初始值，相同的步长来增加id：1写库的id为0,2,4,6…；2写库的id为1,3,5,7…； 不使用数据的id，业务层自己生成唯一的id，保证数据不冲突； 实际中没有使用上述两种架构来做读写的“高可用”，采用的是“双主当主从用”的方式： 仍是双主，但只有一个主提供服务（读+写），另一个主是“shadow-master”，只用来保证高可用，平时不提供服务。 master挂了，shadow-master顶上（vip漂移，对业务层透明，不需要人工介入）。这种方式的好处： 读写没有延时； 读写高可用； 不足： 不能通过加从库的方式扩展读性能； 资源利用率为50%，一台冗余主没有提供服务； 那如何提高读性能呢？进入第二个话题，如何提供读性能。 如何扩展读性能提高读性能的方式大致有三种，第一种是建立索引。这种方式不展开，要提到的一点是，不同的库可以建立不同的索引。 写库不建立索引； 线上读库建立线上访问索引，例如uid； 线下读库建立线下访问索引，例如time； 第二种扩充读性能的方式是，增加从库，这种方法大家用的比较多，但是，存在两个缺点： 从库越多，同步越慢； 同步越慢，数据不一致窗口越大（不一致后面说，还是先说读性能的提高）； 实际中没有采用这种方法提高数据库读性能（没有从库），采用的是增加缓存。常见的缓存架构如下： 上游是业务应用，下游是主库，从库（读写分离），缓存。 实际的玩法：服务+数据库+缓存一套 业务层不直接面向db和cache，服务层屏蔽了底层db、cache的复杂性。为什么要引入服务层，今天不展开，采用了“服务+数据库+缓存一套”的方式提供数据访问，用cache提高读性能。 不管采用主从的方式扩展读性能，还是缓存的方式扩展读性能，数据都要复制多份（主+从，db+cache），一定会引发一致性问题。 如何保证一致性？主从数据库的一致性，通常有两种解决方案： 中间件 如果某一个key有写操作，在不一致时间窗口内，中间件会将这个key的读操作也路由到主库上。这个方案的缺点是，数据库中间件的门槛较高（百度，腾讯，阿里，360等一些公司有）。 强制读主 上面实际用的“双主当主从用”的架构，不存在主从不一致的问题。 第二类不一致，是db与缓存间的不一致： 常见的缓存架构如上，此时写操作的顺序是： 淘汰cache； 写数据库； 读操作的顺序是： 读cache，如果cache hit则返回； 如果cache miss，则读从库； 读从库后，将数据放回cache； 在一些异常时序情况下，有可能从【从库读到旧数据（同步还没有完成），旧数据入cache后】，数据会长期不一致。解决办法是“缓存双淘汰”，写操作时序升级为： 淘汰cache； 写数据库； 在经验“主从同步延时窗口时间”后，再次发起一个异步淘汰cache的请求； 这样，即使有脏数据如cache，一个小的时间窗口之后，脏数据还是会被淘汰。带来的代价是，多引入一次读miss（成本可以忽略）。 除此之外，最佳实践之一是：建议为所有cache中的item设置一个超时时间。 如何提高数据库的扩展性？原来用hash的方式路由，分为2个库，数据量还是太大，要分为3个库，势必需要进行数据迁移，有一个很帅气的“数据库秒级扩容”方案。 如何秒级扩容？ 首先，我们不做2库变3库的扩容，我们做2库变4库（库加倍）的扩容（未来4-&gt;8-&gt;16） 服务+数据库是一套（省去了缓存），数据库采用“双主”的模式。 扩容步骤： 第一步，将一个主库提升; 第二步，修改配置，2库变4库（原来MOD2，现在配置修改后MOD4），扩容完成； 原MOD2为偶的部分，现在会MOD4余0或者2；原MOD2为奇的部分，现在会MOD4余1或者3；数据不需要迁移，同时，双主互相同步，一遍是余0，一边余2，两边数据同步也不会冲突，秒级完成扩容！ 最后，要做一些收尾工作： 将旧的双主同步解除； 增加新的双主（双主是保证可用性的，shadow-master平时不提供服务）； 删除多余的数据（余0的主，可以将余2的数据删除掉）； 这样，秒级别内，我们就完成了2库变4库的扩展。 大并发带来的挑战请求接口的合理设计一个秒杀或者抢购页面，通常分为2个部分，一个是静态的HTML等内容，另一个就是参与秒杀的Web后台请求接口。 通常静态HTML等内容，是通过CDN的部署，一般压力不大，核心瓶颈实际上在后台请求接口上。这个后端接口，必须能够支持高并发请求，同时，非常重要的一点，必须尽可能“快”，在最短的时间里返回用户的请求结果。为了实现尽可能快这一点，接口的后端存储使用内存级别的操作会更好一点。仍然直接面向MySQL之类的存储是不合适的，如果有这种复杂业务的需求，都建议采用异步写入。 当然，也有一些秒杀和抢购采用“滞后反馈”，就是说秒杀当下不知道结果，一段时间后才可以从页面中看到用户是否秒杀成功。但是，这种属于“偷懒”行为，同时给用户的体验也不好，容易被用户认为是“暗箱操作”。 高并发的挑战：一定要“快”我们通常衡量一个Web系统的吞吐率的指标是QPS（Query Per Second，每秒处理请求数），解决每秒数万次的高并发场景，这个指标非常关键。举个例子，我们假设处理一个业务请求平均响应时间为100ms，同时，系统内有20台Apache的Web服务器，配置MaxClients为500个（表示Apache的最大连接数目）。 那么，我们的Web系统的理论峰值QPS为（理想化的计算方式）： 120*500/0.1 = 100000 （10万QPS） 咦？我们的系统似乎很强大，1秒钟可以处理完10万的请求，5w/s的秒杀似乎是“纸老虎”哈。实际情况，当然没有这么理想。在高并发的实际场景下，机器都处于高负载的状态，在这个时候平均响应时间会被大大增加。 就Web服务器而言，Apache打开了越多的连接进程，CPU需要处理的上下文切换也越多，额外增加了CPU的消耗，然后就直接导致平均响应时间增加。因此上述的MaxClient数目，要根据CPU、内存等硬件因素综合考虑，绝对不是越多越好。可以通过Apache自带的abench来测试一下，取一个合适的值。然后，我们选择内存操作级别的存储的Redis，在高并发的状态下，存储的响应时间至关重要。网络带宽虽然也是一个因素，不过，这种请求数据包一般比较小，一般很少成为请求的瓶颈。负载均衡成为系统瓶颈的情况比较少，在这里不做讨论哈。 那么问题来了，假设我们的系统，在5w/s的高并发状态下，平均响应时间从100ms变为250ms（实际情况，甚至更多）： 120*500/0.25 = 40000 （4万QPS） 于是，我们的系统剩下了4w的QPS，面对5w每秒的请求，中间相差了1w。 然后，这才是真正的恶梦开始。举个例子，高速路口，1秒钟来5部车，每秒通过5部车，高速路口运作正常。突然，这个路口1秒钟只能通过4部车，车流量仍然依旧，结果必定出现大塞车。（5条车道忽然变成4条车道的感觉）。 同理，某一个秒内，20*500个可用连接进程都在满负荷工作中，却仍然有1万个新来请求，没有连接进程可用，系统陷入到异常状态也是预期之内。 其实在正常的非高并发的业务场景中，也有类似的情况出现，某个业务请求接口出现问题，响应时间极慢，将整个Web请求响应时间拉得很长，逐渐将Web服务器的可用连接数占满，其他正常的业务请求，无连接进程可用。 更可怕的问题是，是用户的行为特点，系统越是不可用，用户的点击越频繁，恶性循环最终导致“雪崩”（其中一台Web机器挂了，导致流量分散到其他正常工作的机器上，再导致正常的机器也挂，然后恶性循环），将整个Web系统拖垮。 重启与过载保护如果系统发生“雪崩”，贸然重启服务，是无法解决问题的。最常见的现象是，启动起来后，立刻挂掉。这个时候，最好在入口层将流量拒绝，然后再将重启。如果是redis/memcache这种服务也挂了，重启的时候需要注意“预热”，并且很可能需要比较长的时间。 秒杀和抢购的场景，流量往往是超乎我们系统的准备和想象的。这个时候，过载保护是必要的。如果检测到系统满负载状态，拒绝请求也是一种保护措施。在前端设置过滤是最简单的方式，但是，这种做法是被用户“千夫所指”的行为。更合适一点的是，将过载保护设置在CGI入口层，快速将客户的直接请求返回。 作弊的手段：进攻与防守秒杀和抢购收到了“海量”的请求，实际上里面的水分是很大的。不少用户，为了“抢“到商品，会使用“刷票工具”等类型的辅助工具，帮助他们发送尽可能多的请求到服务器。还有一部分高级用户，制作强大的自动请求脚本。这种做法的理由也很简单，就是在参与秒杀和抢购的请求中，自己的请求数目占比越多，成功的概率越高。 这些都是属于“作弊的手段”，不过，有“进攻”就有“防守”，这是一场没有硝烟的战斗哈。 同一个账号，一次性发出多个请求部分用户通过浏览器的插件或者其他工具，在秒杀开始的时间里，以自己的账号，一次发送上百甚至更多的请求。实际上，这样的用户破坏了秒杀和抢购的公平性。 这种请求在某些没有做数据安全处理的系统里，也可能造成另外一种破坏，导致某些判断条件被绕过。例如一个简单的领取逻辑，先判断用户是否有参与记录，如果没有则领取成功，最后写入到参与记录中。这是个非常简单的逻辑，但是，在高并发的场景下，存在深深的漏洞。多个并发请求通过负载均衡服务器，分配到内网的多台Web服务器，它们首先向存储发送查询请求，然后，在某个请求成功写入参与记录的时间差内，其他的请求获查询到的结果都是“没有参与记录”。这里，就存在逻辑判断被绕过的风险。 应对方案： 在程序入口处，一个账号只允许接受1个请求，其他请求过滤。不仅解决了同一个账号，发送N个请求的问题，还保证了后续的逻辑流程的安全。实现方案，可以通过Redis这种内存缓存服务，写入一个标志位（只允许1个请求写成功，结合watch的乐观锁的特性），成功写入的则可以继续参加。 或者，自己实现一个服务，将同一个账号的请求放入一个队列中，处理完一个，再处理下一个。 多个账号，一次性发送多个请求很多公司的账号注册功能，在发展早期几乎是没有限制的，很容易就可以注册很多个账号。因此，也导致了出现了一些特殊的工作室，通过编写自动注册脚本，积累了一大批“僵尸账号”，数量庞大，几万甚至几十万的账号不等，专门做各种刷的行为（这就是微博中的“僵尸粉“的来源）。举个例子，例如微博中有转发抽奖的活动，如果我们使用几万个“僵尸号”去混进去转发，这样就可以大大提升我们中奖的概率。 这种账号，使用在秒杀和抢购里，也是同一个道理。例如，iPhone官网的抢购，火车票黄牛党。 应对方案： 这种场景，可以通过检测指定机器IP请求频率就可以解决，如果发现某个IP请求频率很高，可以给它弹出一个验证码或者直接禁止它的请求： 弹出验证码，最核心的追求，就是分辨出真实用户。因此，大家可能经常发现，网站弹出的验证码，有些是“鬼神乱舞”的样子，有时让我们根本无法看清。他们这样做的原因，其实也是为了让验证码的图片不被轻易识别，因为强大的“自动脚本”可以通过图片识别里面的字符，然后让脚本自动填写验证码。实际上，有一些非常创新的验证码，效果会比较好，例如给你一个简单问题让你回答，或者让你完成某些简单操作（例如百度贴吧的验证码）。 直接禁止IP，实际上是有些粗暴的，因为有些真实用户的网络场景恰好是同一出口IP的，可能会有“误伤“。但是这一个做法简单高效，根据实际场景使用可以获得很好的效果。 多个账号，不同IP发送不同请求所谓道高一尺，魔高一丈。有进攻，就会有防守，永不休止。这些“工作室”，发现你对单机IP请求频率有控制之后，他们也针对这种场景，想出了他们的“新进攻方案”，就是不断改变IP。 有同学会好奇，这些随机IP服务怎么来的。有一些是某些机构自己占据一批独立IP，然后做成一个随机代理IP的服务，有偿提供给这些“工作室”使用。还有一些更为黑暗一点的，就是通过木马黑掉普通用户的电脑，这个木马也不破坏用户电脑的正常运作，只做一件事情，就是转发IP包，普通用户的电脑被变成了IP代理出口。通过这种做法，黑客就拿到了大量的独立IP，然后搭建为随机IP服务，就是为了挣钱。 应对方案： 说实话，这种场景下的请求，和真实用户的行为，已经基本相同了，想做分辨很困难。再做进一步的限制很容易“误伤“真实用户，这个时候，通常只能通过设置业务门槛高来限制这种请求了，或者通过账号行为的”数据挖掘“来提前清理掉它们。 僵尸账号也还是有一些共同特征的，例如账号很可能属于同一个号码段甚至是连号的，活跃度不高，等级低，资料不全等等。根据这些特点，适当设置参与门槛，例如限制参与秒杀的账号等级。通过这些业务手段，也是可以过滤掉一些僵尸号。 高并发下的数据安全我们知道在多线程写入同一个文件的时候，会存现“线程安全”的问题（多个线程同时运行同一段代码，如果每次运行结果和单线程运行的结果是一样的，结果和预期相同，就是线程安全的）。如果是MySQL数据库，可以使用它自带的锁机制很好的解决问题，但是，在大规模并发的场景中，是不推荐使用MySQL的。秒杀和抢购的场景中，还有另外一个问题，就是“超发”，如果在这方面控制不慎，会产生发送过多的情况。我们也曾经听说过，某些电商搞抢购活动，买家成功拍下后，商家却不承认订单有效，拒绝发货。这里的问题，也许并不一定是商家奸诈，而是系统技术层面存在超发风险导致的。 超发的原因假设某个抢购场景中，我们一共只有100个商品，在最后一刻，我们已经消耗了99个商品，仅剩最后一个。这个时候，系统发来多个并发请求，这批请求读取到的商品余量都是99个，然后都通过了这一个余量判断，最终导致超发。 在上面的这个图中，就导致了并发用户B也“抢购成功”，多让一个人获得了商品。这种场景，在高并发的情况下非常容易出现。 悲观锁思路解决线程安全的思路很多，可以从“悲观锁”的方向开始讨论。 悲观锁，也就是在修改数据的时候，采用锁定状态，排斥外部请求的修改。遇到加锁的状态，就必须等待。 虽然上述的方案的确解决了线程安全的问题，但是，别忘记，我们的场景是“高并发”。也就是说，会很多这样的修改请求，每个请求都需要等待“锁”，某些线程可能永远都没有机会抢到这个“锁”，这种请求就会死在那里。同时，这种请求会很多，瞬间增大系统的平均响应时间，结果是可用连接数被耗尽，系统陷入异常。 FIFO队列思路那好，那么我们稍微修改一下上面的场景，我们直接将请求放入队列中的，采用FIFO（First Input First Output，先进先出），这样的话，我们就不会导致某些请求永远获取不到锁。看到这里，是不是有点强行将多线程变成单线程的感觉哈。 然后，我们现在解决了锁的问题，全部请求采用“先进先出”的队列方式来处理。那么新的问题来了，高并发的场景下，因为请求很多，很可能一瞬间将队列内存“撑爆”，然后系统又陷入到了异常状态。或者设计一个极大的内存队列，也是一种方案，但是，系统处理完一个队列内请求的速度根本无法和疯狂涌入队列中的数目相比。也就是说，队列内的请求会越积累越多，最终Web系统平均响应时候还是会大幅下降，系统还是陷入异常。 乐观锁思路这个时候，我们就可以讨论一下“乐观锁”的思路了。乐观锁，是相对于“悲观锁”采用更为宽松的加锁机制，大都是采用带版本号（Version）更新。实现就是，这个数据所有请求都有资格去修改，但会获得一个该数据的版本号，只有版本号符合的才能更新成功，其他的返回抢购失败。这样的话，我们就不需要考虑队列的问题，不过，它会增大CPU的计算开销。但是，综合来说，这是一个比较好的解决方案。 有很多软件和服务都“乐观锁”功能的支持，例如Redis中的watch就是其中之一。通过这个实现，我们保证了数据的安全。 总结互联网正在高速发展，使用互联网服务的用户越多，高并发的场景也变得越来越多。电商秒杀和抢购，是两个比较典型的互联网高并发场景。虽然我们解决问题的具体技术方案可能千差万别，但是遇到的挑战却是相似的，因此解决问题的思路也异曲同工。 原文出处：oschina","categories":[{"name":"架构","slug":"架构","permalink":"http://zeco.oschina.io/categories/架构/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://zeco.oschina.io/tagcloud/Redis/"},{"name":"quene","slug":"quene","permalink":"http://zeco.oschina.io/tagcloud/quene/"},{"name":"秒杀","slug":"秒杀","permalink":"http://zeco.oschina.io/tagcloud/秒杀/"}]},{"title":"进击的分布式架构(III)[转]","slug":"web_3","date":"un55fin55","updated":"un66fin66","comments":true,"path":"2017/04/28/web_3/","link":"","permalink":"http://zeco.oschina.io/2017/04/28/web_3/","excerpt":"异地部署（地理分布式）完成了上述架构建设之后，我们的系统是否就已经足够强大了呢？答案当然是否定的哈，优化是无极限的。Web系统虽然表面上看，似乎比较强大了，但是给予用户的体验却不一定是最好的。因为东北的同学，访问深圳的一个网站服务，他还是会感到一些网络距离上的慢。这个时候，我们就需要做异地部署，让Web系统离用户更近。","text":"异地部署（地理分布式）完成了上述架构建设之后，我们的系统是否就已经足够强大了呢？答案当然是否定的哈，优化是无极限的。Web系统虽然表面上看，似乎比较强大了，但是给予用户的体验却不一定是最好的。因为东北的同学，访问深圳的一个网站服务，他还是会感到一些网络距离上的慢。这个时候，我们就需要做异地部署，让Web系统离用户更近。 一、 核心集中与节点分散有玩过大型网游的同学都会知道，网游是有很多个区的，一般都是按照地域来分，例如广东专区，北京专区。如果一个在广东的玩家，去北京专区玩，那么他会感觉明显比在广东专区卡。实际上，这些大区的名称就已经说明了，它的服务器所在地，所以，广东的玩家去连接地处北京的服务器，网络当然会比较慢。 当一个系统和服务足够大的时候，就必须开始考虑异地部署的问题了。让你的服务，尽可能离用户更近。我们前面已经提到了Web的静态资源，可以存放在CDN上，然后通过DNS/GSLB的方式，让静态资源的分散“全国各地”。但是，CDN只解决的静态资源的问题，没有解决后端庞大的系统服务还只集中在某个固定城市的问题。 这个时候，异地部署就开始了。异地部署一般遵循：核心集中，节点分散。 核心集中：实际部署过程中，总有一部分的数据和服务存在不可部署多套，或者部署多套成本巨大。而对于这些服务和数据，就仍然维持一套，而部署地点选择一个地域比较中心的地方，通过网络内部专线来和各个节点通讯。 节点分散：将一些服务部署为多套，分布在各个城市节点，让用户请求尽可能选择近的节点访问服务。 例如，我们选择在上海部署为核心节点，北京，深圳，武汉，上海为分散节点（上海自己本身也是一个分散节点）。我们的服务架构如图： 需要补充一下的是，上图中上海节点和核心节点是同处于一个机房的，其他分散节点各自独立机房。国内有很多大型网游，都是大致遵循上述架构。它们会把数据量不大的用户核心账号等放在核心节点，而大部分的网游数据，例如装备、任务等数据和服务放在地区节点里。当然，核心节点和地域节点之间，也有缓存机制。 二、 节点容灾和过载保护节点容灾是指，某个节点如果发生故障时，我们需要建立一个机制去保证服务仍然可用。毫无疑问，这里比较常见的容灾方式，是切换到附近城市节点。假如系统的天津节点发生故障，那么我们就将网络流量切换到附近的北京节点上。考虑到负载均衡，可能需要同时将流量切换到附近的几个地域节点。另一方面，核心节点自身也是需要自己做好容灾和备份的，核心节点一旦故障，就会影响全国服务。 过载保护，指的是一个节点已经达到最大容量，无法继续接接受更多请求了，系统必须有一个保护的机制。一个服务已经满负载，还继续接受新的请求，结果很可能就是宕机，影响整个节点的服务，为了至少保障大部分用户的正常使用，过载保护是必要的。 解决过载保护，一般2个方向： 拒绝服务，检测到满负载之后，就不再接受新的连接请求。例如网游登入中的排队。 分流到其他节点。这种的话，系统实现更为复杂，又涉及到负载均衡的问题。 小结Web系统会随着访问规模的增长，渐渐地从1台服务器可以满足需求，一直成长为“庞然大物”的大集群。而这个Web系统变大的过程，实际上就是我们解决问题的过程。在不同的阶段，解决不同的问题，而新的问题又诞生在旧的解决方案之上。 系统的优化是没有极限的，软件和系统架构也一直在快速发展，新的方案解决了老的问题，同时也带来新的挑战。","categories":[{"name":"架构","slug":"架构","permalink":"http://zeco.oschina.io/categories/架构/"}],"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"http://zeco.oschina.io/tagcloud/负载均衡/"},{"name":"缓存机制","slug":"缓存机制","permalink":"http://zeco.oschina.io/tagcloud/缓存机制/"},{"name":"异地部署","slug":"异地部署","permalink":"http://zeco.oschina.io/tagcloud/异地部署/"}]},{"title":"进击的分布式架构(II)[转]","slug":"web_2","date":"un33fin33","updated":"un66fin66","comments":true,"path":"2017/04/19/web_2/","link":"","permalink":"http://zeco.oschina.io/2017/04/19/web_2/","excerpt":"Web系统的缓存机制的建立和优化刚刚我们讲完了Web系统的外部网络环境，现在我们开始关注我们Web系统自身的性能问题。我们的Web站点随着访问量的上升，会遇到很多的挑战，解决这些问题不仅仅是扩容机器这么简单，建立和使用合适的缓存机制才是根本。 最开始，我们的Web系统架构可能是这样的，每个环节，都可能只有1台机器。","text":"Web系统的缓存机制的建立和优化刚刚我们讲完了Web系统的外部网络环境，现在我们开始关注我们Web系统自身的性能问题。我们的Web站点随着访问量的上升，会遇到很多的挑战，解决这些问题不仅仅是扩容机器这么简单，建立和使用合适的缓存机制才是根本。 最开始，我们的Web系统架构可能是这样的，每个环节，都可能只有1台机器。 我们从最根本的数据存储开始看。 一、 MySQL数据库内部缓存使用MySQL的缓存机制，就从先从MySQL内部开始，下面的内容将以最常见的InnoDB存储引擎为主。 1. 建立恰当的索引最简单的是建立索引，索引在表数据比较大的时候，起到快速检索数据的作用，但是成本也是有的。首先，占用了一定的磁盘空间，其中组合索引最突出，使用需要谨慎，它产生的索引甚至会比源数据更大。其次，建立索引之后的数据insert/update/delete等操作，因为需要更新原来的索引，耗时会增加。当然，实际上我们的系统从总体来说，是以select查询操作居多，因此，索引的使用仍然对系统性能有大幅提升的作用。 2. 数据库连接线程池缓存如果，每一个数据库操作请求都需要创建和销毁连接的话，对数据库来说，无疑也是一种巨大的开销。为了减少这类型的开销，可以在MySQL中配置thread_cache_size来表示保留多少线程用于复用。线程不够的时候，再创建，空闲过多的时候，则销毁。 其实，还有更为激进一点的做法，使用pconnect（数据库长连接），线程一旦创建在很长时间内都保持着。但是，在访问量比较大，机器比较多的情况下，这种用法很可能会导致“数据库连接数耗尽”，因为建立连接并不回收，最终达到数据库的max_connections（最大连接数）。因此，长连接的用法通常需要在CGI和MySQL之间实现一个“连接池”服务，控制CGI机器“盲目”创建连接数。 建立数据库连接池服务，有很多实现的方式，PHP的话，我推荐使用swoole（PHP的一个网络通讯拓展）来实现。 3. Innodb缓存设置（innodb_buffer_pool_size）innodb_buffer_pool_size这是个用来保存索引和数据的内存缓存区，如果机器是MySQL独占的机器，一般推荐为机器物理内存的80%。在取表数据的场景中，它可以减少磁盘IO。一般来说，这个值设置越大，cache命中率会越高。 4. 分库/分表/分区。MySQL数据库表一般承受数据量在百万级别，再往上增长，各项性能将会出现大幅度下降，因此，当我们预见数据量会超过这个量级的时候，建议进行分库/分表/分区等操作。最好的做法，是服务在搭建之初就设计为分库分表的存储模式，从根本上杜绝中后期的风险。不过，会牺牲一些便利性，例如列表式的查询，同时，也增加了维护的复杂度。不过，到了数据量千万级别或者以上的时候，我们会发现，它们都是值得的。 二、 MySQL数据库多台服务搭建1台MySQL机器，实际上是高风险的单点，因为如果它挂了，我们Web服务就不可用了。而且，随着Web系统访问量继续增加，终于有一天，我们发现1台MySQL服务器无法支撑下去，我们开始需要使用更多的MySQL机器。当引入多台MySQL机器的时候，很多新的问题又将产生。 1. 建立MySQL主从，从库作为备份这种做法纯粹为了解决“单点故障”的问题，在主库出故障的时候，切换到从库。不过，这种做法实际上有点浪费资源，因为从库实际上被闲着了。 2. MySQL读写分离，主库写，从库读。两台数据库做读写分离，主库负责写入类的操作，从库负责读的操作。并且，如果主库发生故障，仍然不影响读的操作，同时也可以将全部读写都临时切换到从库中（需要注意流量，可能会因为流量过大，把从库也拖垮）。 3. 主主互备。两台MySQL之间互为彼此的从库，同时又是主库。这种方案，既做到了访问量的压力分流，同时也解决了“单点故障”问题。任何一台故障，都还有另外一套可供使用的服务。 不过，这种方案，只能用在两台机器的场景。如果业务拓展还是很快的话，可以选择将业务分离，建立多个主主互备。 三、 MySQL数据库机器之间的数据同步每当我们解决一个问题，新的问题必然诞生在旧的解决方案上。当我们有多台MySQL，在业务高峰期，很可能出现两个库之间的数据有延迟的场景。并且，网络和机器负载等，也会影响数据同步的延迟。我们曾经遇到过，在日访问量接近1亿的特殊场景下，出现，从库数据需要很多天才能同步追上主库的数据。这种场景下，从库基本失去效用了。 于是，解决同步问题，就是我们下一步需要关注的点。 1. MySQL自带多线程同步MySQL5.6开始支持主库和从库数据同步，走多线程。但是，限制也是比较明显的，只能以库为单位。MySQL数据同步是通过binlog日志，主库写入到binlog日志的操作，是具有顺序的，尤其当SQL操作中含有对于表结构的修改等操作，对于后续的SQL语句操作是有影响的。因此，从库同步数据，必须走单进程。 2. 自己实现解析binlog，多线程写入。以数据库的表为单位，解析binlog多张表同时做数据同步。这样做的话，的确能够加快数据同步的效率，但是，如果表和表之间存在结构关系或者数据依赖的话，则同样存在写入顺序的问题。这种方式，可用于一些比较稳定并且相对独立的数据表。 国内一线互联网公司，大部分都是通过这种方式，来加快数据同步效率。还有更为激进的做法，是直接解析binlog，忽略以表为单位，直接写入。但是这种做法，实现复杂，使用范围就更受到限制，只能用于一些场景特殊的数据库中（没有表结构变更，表和表之间没有数据依赖等特殊表）。 四、 在Web服务器和数据库之间建立缓存实际上，解决大访问量的问题，不能仅仅着眼于数据库层面。根据“二八定律”，80%的请求只关注在20%的热点数据上。因此，我们应该建立Web服务器和数据库之间的缓存机制。这种机制，可以用磁盘作为缓存，也可以用内存缓存的方式。通过它们，将大部分的热点数据查询，阻挡在数据库之前。 1. 页面静态化用户访问网站的某个页面，页面上的大部分内容在很长一段时间内，可能都是没有变化的。例如一篇新闻报道，一旦发布几乎是不会修改内容的。这样的话，通过CGI生成的静态html页面缓存到Web服务器的磁盘本地。除了第一次，是通过动态CGI查询数据库获取之外，之后都直接将本地磁盘文件返回给用户。 在Web系统规模比较小的时候，这种做法看似完美。但是，一旦Web系统规模变大，例如当我有100台的Web服务器的时候。那样这些磁盘文件，将会有100份，这个是资源浪费，也不好维护。这个时候有人会想，可以集中一台服务器存起来，呵呵，不如看看下面一种缓存方式吧，它就是这样做的。 2. 单台内存缓存通过页面静态化的例子中，我们可以知道将“缓存”搭建在Web机器本机是不好维护的，会带来更多问题（实际上，通过PHP的apc拓展，可通过Key/value操作Web服务器的本机内存）。因此，我们选择搭建的内存缓存服务，也必须是一个独立的服务。 内存缓存的选择，主要有redis/memcache。从性能上说，两者差别不大，从功能丰富程度上说，Redis更胜一筹。 3. 内存缓存集群当我们搭建单台内存缓存完毕，我们又会面临单点故障的问题，因此，我们必须将它变成一个集群。简单的做法，是给他增加一个slave作为备份机器。但是，如果请求量真的很多，我们发现cache命中率不高，需要更多的机器内存呢？因此，我们更建议将它配置成一个集群。例如，类似redis cluster。 Redis cluster集群内的Redis互为多组主从，同时每个节点都可以接受请求，在拓展集群的时候比较方便。客户端可以向任意一个节点发送请求，如果是它的“负责”的内容，则直接返回内容。否则，查找实际负责Redis节点，然后将地址告知客户端，客户端重新请求。 对于使用缓存服务的客户端来说，这一切是透明的。 内存缓存服务在切换的时候，是有一定风险的。从A集群切换到B集群的过程中，必须保证B集群提前做好“预热”（B集群的内存中的热点数据，应该尽量与A集群相同，否则，切换的一瞬间大量请求内容，在B集群的内存缓存中查找不到，流量直接冲击后端的数据库服务，很可能导致数据库宕机）。 4. 减少数据库“写”上面的机制，都实现减少数据库的“读”的操作，但是，写的操作也是一个大的压力。写的操作，虽然无法减少，但是可以通过合并请求，来起到减轻压力的效果。这个时候，我们就需要在内存缓存集群和数据库集群之间，建立一个修改同步机制。 先将修改请求生效在cache中，让外界查询显示正常，然后将这些sql修改放入到一个队列中存储起来，队列满或者每隔一段时间，合并为一个请求到数据库中更新数据库。 除了上述通过改变系统架构的方式提升写的性能外，MySQL本身也可以通过配置参数innodb_flush_log_at_trx_commit来调整写入磁盘的策略。如果机器成本允许，从硬件层面解决问题，可以选择老一点的RAID（Redundant Arrays of independent Disks，磁盘列阵）或者比较新的SSD（Solid State Drives，固态硬盘）。 5. NoSQL存储不管数据库的读还是写，当流量再进一步上涨，终会达到“人力有穷时”的场景。继续加机器的成本比较高，并且不一定可以真正解决问题的时候。这个时候，部分核心数据，就可以考虑使用NoSQL的数据库。NoSQL存储，大部分都是采用key-value的方式，这里比较推荐使用上面介绍过Redis，Redis本身是一个内存cache，同时也可以当做一个存储来使用，让它直接将数据落地到磁盘。 这样的话，我们就将数据库中某些被频繁读写的数据，分离出来，放在我们新搭建的Redis存储集群中，又进一步减轻原来MySQL数据库的压力，同时因为Redis本身是个内存级别的Cache，读写的性能都会大幅度提升。 国内一线互联网公司，架构上采用的解决方案很多是类似于上述方案，不过，使用的cache服务却不一定是Redis，他们会有更丰富的其他选择，甚至根据自身业务特点开发出自己的NoSQL服务。 6. 空节点查询问题当我们搭建完前面所说的全部服务，认为Web系统已经很强的时候。我们还是那句话，新的问题还是会来的。空节点查询，是指那些数据库中根本不存在的数据请求。例如，我请求查询一个不存在人员信息，系统会从各级缓存逐级查找，最后查到到数据库本身，然后才得出查找不到的结论，返回给前端。因为各级cache对它无效，这个请求是非常消耗系统资源的，而如果大量的空节点查询，是可以冲击到系统服务的。 在我曾经的工作经历中，曾深受其害。因此，为了维护Web系统的稳定性，设计适当的空节点过滤机制，非常有必要。 我们当时采用的方式，就是设计一张简单的记录映射表。将存在的记录存储起来，放入到一台内存cache中，这样的话，如果还有空节点查询，则在缓存这一层就被阻挡了。","categories":[{"name":"架构","slug":"架构","permalink":"http://zeco.oschina.io/categories/架构/"}],"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"http://zeco.oschina.io/tagcloud/负载均衡/"},{"name":"缓存机制","slug":"缓存机制","permalink":"http://zeco.oschina.io/tagcloud/缓存机制/"},{"name":"异地部署","slug":"异地部署","permalink":"http://zeco.oschina.io/tagcloud/异地部署/"}]},{"title":"进击的分布式架构(I)[转]","slug":"web","date":"un33fin33","updated":"un66fin66","comments":true,"path":"2017/04/05/web/","link":"","permalink":"http://zeco.oschina.io/2017/04/05/web/","excerpt":"当一个Web系统从日访问量10万逐步增长到1000万，甚至超过1亿的过程中，Web系统承受的压力会越来越大，在这个过程中，我们会遇到很多的问题。为了解决这些性能压力带来问题，我们需要在Web系统架构层面搭建多个层次的缓存机制。在不同的压力阶段，我们会遇到不同的问题，通过搭建不同的服务和架构来解决。 Web负载均衡Web负载均衡（Load Balancing），简单地说就是给我们的服务器集群分配“工作任务”，而采用恰当的分配方式，对于保护处于后端的Web服务器来说，非常重要。","text":"当一个Web系统从日访问量10万逐步增长到1000万，甚至超过1亿的过程中，Web系统承受的压力会越来越大，在这个过程中，我们会遇到很多的问题。为了解决这些性能压力带来问题，我们需要在Web系统架构层面搭建多个层次的缓存机制。在不同的压力阶段，我们会遇到不同的问题，通过搭建不同的服务和架构来解决。 Web负载均衡Web负载均衡（Load Balancing），简单地说就是给我们的服务器集群分配“工作任务”，而采用恰当的分配方式，对于保护处于后端的Web服务器来说，非常重要。 负载均衡的策略有很多，我们从简单的讲起哈。 1. HTTP重定向当用户发来请求的时候，Web服务器通过修改HTTP响应头中的Location标记来返回一个新的url，然后浏览器再继续请求这个新url，实际上就是页面重定向。通过重定向，来达到“负载均衡”的目标。例如，我们在下载PHP源码包的时候，点击下载链接时，为了解决不同国家和地域下载速度的问题，它会返回一个离我们近的下载地址。重定向的HTTP返回码是302，如下图： 如果使用PHP代码来实现这个功能，方式如下： 这个重定向非常容易实现，并且可以自定义各种策略。但是，它在大规模访问量下，性能不佳。而且，给用户的体验也不好，实际请求发生重定向，增加了网络延时。 2. 反向代理负载均衡反向代理服务的核心工作主要是转发HTTP请求，扮演了浏览器端和后台Web服务器中转的角色。因为它工作在HTTP层（应用层），也就是网络七层结构中的第七层，因此也被称为“七层负载均衡”。可以做反向代理的软件很多，比较常见的一种是Nginx。 Nginx是一种非常灵活的反向代理软件，可以自由定制化转发策略，分配服务器流量的权重等。反向代理中，常见的一个问题，就是Web服务器存储的session数据，因为一般负载均衡的策略都是随机分配请求的。同一个登录用户的请求，无法保证一定分配到相同的Web机器上，会导致无法找到session的问题。 解决方案主要有两种： 配置反向代理的转发规则，让同一个用户的请求一定落到同一台机器上（通过分析cookie），复杂的转发规则将会消耗更多的CPU，也增加了代理服务器的负担。 将session这类的信息，专门用某个独立服务来存储，例如redis/memchache，这个方案是比较推荐的。 反向代理服务，也是可以开启缓存的，如果开启了，会增加反向代理的负担，需要谨慎使用。这种负载均衡策略实现和部署非常简单，而且性能表现也比较好。但是，它有“单点故障”的问题，如果挂了，会带来很多的麻烦。而且，到了后期Web服务器继续增加，它本身可能成为系统的瓶颈。 3. IP负载均衡IP负载均衡服务是工作在网络层（修改IP）和传输层（修改端口，第四层），比起工作在应用层（第七层）性能要高出非常多。原理是，他是对IP层的数据包的IP地址和端口信息进行修改，达到负载均衡的目的。这种方式，也被称为“四层负载均衡”。常见的负载均衡方式，是LVS（Linux Virtual Server，Linux虚拟服务），通过IPVS（IP Virtual Server，IP虚拟服务）来实现。 在负载均衡服务器收到客户端的IP包的时候，会修改IP包的目标IP地址或端口，然后原封不动地投递到内部网络中，数据包会流入到实际Web服务器。实际服务器处理完成后，又会将数据包投递回给负载均衡服务器，它再修改目标IP地址为用户IP地址，最终回到客户端。 上述的方式叫LVS-NAT，除此之外，还有LVS-RD（直接路由），LVS-TUN（IP隧道），三者之间都属于LVS的方式，但是有一定的区别，篇幅问题，不赘叙。 IP负载均衡的性能要高出Nginx的反向代理很多，它只处理到传输层为止的数据包，并不做进一步的组包，然后直接转发给实际服务器。不过，它的配置和搭建比较复杂。 4. DNS负载均衡DNS（Domain Name System）负责域名解析的服务，域名url实际上是服务器的别名，实际映射是一个IP地址，解析过程，就是DNS完成域名到IP的映射。而一个域名是可以配置成对应多个IP的。因此，DNS也就可以作为负载均衡服务。 这种负载均衡策略，配置简单，性能极佳。但是，不能自由定义规则，而且，变更被映射的IP或者机器故障时很麻烦，还存在DNS生效延迟的问题。 5. DNS/GSLB负载均衡我们常用的CDN（Content Delivery Network，内容分发网络）实现方式，其实就是在同一个域名映射为多IP的基础上更进一步，通过GSLB（Global Server Load Balance，全局负载均衡）按照指定规则映射域名的IP。一般情况下都是按照地理位置，将离用户近的IP返回给用户，减少网络传输中的路由节点之间的跳跃消耗。 图中的“向上寻找”，实际过程是LDNS（Local DNS）先向根域名服务（Root Name Server）获取到顶级根的Name Server（例如.com的），然后得到指定域名的授权DNS，然后再获得实际服务器IP。 CDN在Web系统中，一般情况下是用来解决大小较大的静态资源（html/Js/Css/图片等）的加载问题，让这些比较依赖网络下载的内容，尽可能离用户更近，提升用户体验。 例如，我访问了一张imgcache.gtimg.cn上的图片（腾讯的自建CDN，不使用qq.com域名的原因是防止http请求的时候，带上了多余的cookie信息），我获得的IP是183.60.217.90。 这种方式，和前面的DNS负载均衡一样，不仅性能极佳，而且支持配置多种策略。但是，搭建和维护成本非常高。互联网一线公司，会自建CDN服务，中小型公司一般使用第三方提供的CDN。","categories":[{"name":"架构","slug":"架构","permalink":"http://zeco.oschina.io/categories/架构/"}],"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"http://zeco.oschina.io/tagcloud/负载均衡/"},{"name":"缓存机制","slug":"缓存机制","permalink":"http://zeco.oschina.io/tagcloud/缓存机制/"},{"name":"异地部署","slug":"异地部署","permalink":"http://zeco.oschina.io/tagcloud/异地部署/"}]},{"title":"网站设计中的cache技术","slug":"cache_1","date":"un44fin44","updated":"un00fin00","comments":true,"path":"2017/03/02/cache_1/","link":"","permalink":"http://zeco.oschina.io/2017/03/02/cache_1/","excerpt":"页面缓存的原理大体是在浏览器对资源的第一次请求之后，把资源中的一部分存储在计算机的临时文件空间，再次请求的时候，按照特定的策略加载缓存的资源，减少HTTP请求次数与传输数据量，以此提高浏览效率，减少数据库和服务器的压力。 在网站设计时要充分考虑缓存，合理的利用缓存和静态技术可以大大的提高网站的运行速度。","text":"页面缓存的原理大体是在浏览器对资源的第一次请求之后，把资源中的一部分存储在计算机的临时文件空间，再次请求的时候，按照特定的策略加载缓存的资源，减少HTTP请求次数与传输数据量，以此提高浏览效率，减少数据库和服务器的压力。 在网站设计时要充分考虑缓存，合理的利用缓存和静态技术可以大大的提高网站的运行速度。 页面静态化将动态的页面生成静态的页面保存下来，但用户访问特定的页面时，直接将缓存好的静态页面返回给客户，省去了去数据库读取数据的过程，大大提高了网站的运行效率，降低了数据库的压力。 这里牺牲了网站数据的及时性，一般静态化缓存会和其他技术结合起来使用，而不是单独使用。 php里一般使用ob方法来实现页面静态缓存123ob_start();$content = ob_get_contents();ob_end_clean(); 页面部分静态化使用模块化设计，将不需要数据动态化的部分进行静态化，使用ob函数输出，也可以使用其他技术，如ESI。 一般即使动态的数据，如果数据变化不是十分频繁（我们通过设计固定时间来更新我们的数据），也可以通过一些标识（如：id）来保存静态化数据的页面，然后通过（id）来找到静态页面位置，当该页面被访问时，直接返回给用户。 这里需要设计人员分割是否需要动态数据显示 memcached（redis）缓存内存缓存，一般使用memcached或者redis来实现，将数据以key&amp;value的方式保存在内存中，因为数据缓存在内存中，无需再去数据库里读取，这样不仅大大减轻了数据库的压力，也一样提升网站的处理速度。 这里要注意memcached和redis的选用，如果只是单纯的key&amp;value的数据读取，那么memecached是不错的选择，如果对数据安全有要求，又需要比较复杂的数据存储形式，那么redis可能会更加适合你。具体详见Memcached和Redis 关于缓存缓存有时候是让人讨厌的东西，但对于网页设计确实不得不去考虑的东西，这里简单的列举了三个比较常见的缓存技术，当然还有许多其他的缓存技术，留待以后慢慢的整理。","categories":[{"name":"php","slug":"php","permalink":"http://zeco.oschina.io/categories/php/"},{"name":"静态技术","slug":"php/静态技术","permalink":"http://zeco.oschina.io/categories/php/静态技术/"}],"tags":[{"name":"cache","slug":"cache","permalink":"http://zeco.oschina.io/tagcloud/cache/"},{"name":"php","slug":"php","permalink":"http://zeco.oschina.io/tagcloud/php/"}]},{"title":"使用phpspider开发的PHP爬虫","slug":"phpspider_1","date":"un22fin22","updated":"un66fin66","comments":true,"path":"2017/01/17/phpspider_1/","link":"","permalink":"http://zeco.oschina.io/2017/01/17/phpspider_1/","excerpt":"开源库出处：Github 开发框架phpspider是一个爬虫开发框架。使用本框架，你不用了解爬虫的底层技术实现，爬虫被网站屏蔽、有些网站需要登录或验证码识别才能爬取等问题。简单几行PHP代码，就可以创建自己的爬虫，利用框架封装的多进程Worker类库，代码更简洁，执行效率更高速度更快。","text":"开源库出处：Github 开发框架phpspider是一个爬虫开发框架。使用本框架，你不用了解爬虫的底层技术实现，爬虫被网站屏蔽、有些网站需要登录或验证码识别才能爬取等问题。简单几行PHP代码，就可以创建自己的爬虫，利用框架封装的多进程Worker类库，代码更简洁，执行效率更高速度更快。demo目录下有一些特定网站的爬取规则，只要你安装了PHP环境，代码就可以在命令行下直接跑。 糗事百科案例1234567891011121314151617181920212223242526272829303132$configs = array( &apos;name&apos; =&gt; &apos;糗事百科&apos;, &apos;domains&apos; =&gt; array( &apos;qiushibaike.com&apos;, &apos;www.qiushibaike.com&apos; ), &apos;scan_urls&apos; =&gt; array( &apos;http://www.qiushibaike.com/&apos; ), &apos;content_url_regexes&apos; =&gt; array( &quot;http://www.qiushibaike.com/article/\\d+&quot; ), &apos;list_url_regexes&apos; =&gt; array( &quot;http://www.qiushibaike.com/8hr/page/\\d+\\?s=\\d+&quot; ), &apos;fields&apos; =&gt; array( array( // 抽取内容页的文章内容 &apos;name&apos; =&gt; &quot;article_content&quot;, &apos;selector&apos; =&gt; &quot;//*[@id=&apos;single-next-link&apos;]&quot;, &apos;required&apos; =&gt; true ), array( // 抽取内容页的文章作者 &apos;name&apos; =&gt; &quot;article_author&quot;, &apos;selector&apos; =&gt; &quot;//div[contains(@class,&apos;author&apos;)]//h2&quot;, &apos;required&apos; =&gt; true ), ), ); $spider = new phpspider($configs); $spider-&gt;start(); 爬虫程序设计因为爬取的页面需要登录才能获取到关注者页面，所以从chrome登录之后把cookie拷贝下来给curl程序模拟登录。 使用两大独立循环进程组(用户索引进程组、用户详情进程组)，用的是php的pcntl扩展，封装了一个非常好用的类，使用起来和golang的携程也差不多了。 用户索引进程组先以一个用户为起点，抓取这个用户的关注了和关注者，然后合并入库，因为是多进程，所以当有两个进程在处理同一个用户入库的时候就会出现重复的用户，所以数据库用户名字段一定要建立唯一索引，当然也可以用redis这些第三方缓存来保证原子性，这个就见仁见智了。 用户详情进程组按照时间正序，拿到最先入库的用户抓取详情，并且把更新时间更新为当前时间，这样就可以变成一个死循环，程序可以无休止的跑，不断的循环更新用户信息。 程序运行过程中出现的错误,因为网站会给数据强制gzip压缩，需要通过解压来获取有效数据 $content = substr($content, 10);$content = gzinflate($content));curl_setopt( self::$ch, CURLOPT_ENCODING, ‘gzip’ ); 获取数据的作用（感想）将一堆数据进行分类分析，通过数据的分布可以分析出平常不易看出来的规律，对于我们的决策有很大的指引意义。 原文出处：event poll","categories":[{"name":"数据技术","slug":"数据技术","permalink":"http://zeco.oschina.io/categories/数据技术/"},{"name":"爬虫","slug":"数据技术/爬虫","permalink":"http://zeco.oschina.io/categories/数据技术/爬虫/"}],"tags":[{"name":"拿来的东西","slug":"拿来的东西","permalink":"http://zeco.oschina.io/tagcloud/拿来的东西/"},{"name":"爬虫","slug":"爬虫","permalink":"http://zeco.oschina.io/tagcloud/爬虫/"}]},{"title":"redis vs memecached","slug":"redis_vs_mem","date":"un66fin66","updated":"un11fin11","comments":true,"path":"2016/12/03/redis_vs_mem/","link":"","permalink":"http://zeco.oschina.io/2016/12/03/redis_vs_mem/","excerpt":"Redis 是由来自意大利西西里岛的Salvatore Sanfilippo开发的一款开源的，使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库。 这里不得不说一个勤奋的作者对一款开源软件是一件很重要的事，时至今日，与前辈memcached相比，Redis在大多数方面已经完成了全面的超越。 下面摘录一段在stackoverflow上看到关于redis的文章。","text":"Redis 是由来自意大利西西里岛的Salvatore Sanfilippo开发的一款开源的，使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库。 这里不得不说一个勤奋的作者对一款开源软件是一件很重要的事，时至今日，与前辈memcached相比，Redis在大多数方面已经完成了全面的超越。 下面摘录一段在stackoverflow上看到关于redis的文章。 Redis is more powerful, more popular, and better supported than memcached. Memcached can only do a small fraction of the things Redis can do. Redis is better even where their features overlap.For anything new, use Redis. Redis拥有着更加强大和丰富的功能 Memcached vs Redis: Direct ComparisonBoth tools are powerful, fast, in-memory data stores that are useful as a cache. Both can help speed up your application by caching database results, HTML fragments, or anything else that might be expensive to generate. 两者都是通过使用内存缓存，来帮助你的网站提速 Points to Consider1. Read/write speed: Both are extremely fast. Benchmarks vary by workload, versions, and many other factors but generally show redis to be as fast or almost as fast as memcached. I recommend redis, but not because memcached is slow. It&apos;s not. 2. Memory usage: Redis is better. memcached: You specify the cache size and as you insert items the daemon quickly grows to a little more than this size. There is never really a way to reclaim any of that space, short of restarting memcached. All your keys could be expired, you could flush the database, and it would still use the full chunk of RAM you configured it with. redis: Setting a max size is up to you. Redis will never use more than it has to and will give you back memory it is no longer using. I stored 100,000 ~2KB strings (~200MB) of random sentences into both. Memcached RAM usage grew to ~225MB. Redis RAM usage grew to ~228MB. After flushing both, redis dropped to ~29MB and memcached stayed at ~225MB. They are similarly efficient in how they store data, but only one is capable of reclaiming it. 3. Disk I/O dumping: A clear win for redis since it does this by default and has very configurable persistence. Memcached has no mechanisms for dumping to disk without 3rd party tools. 4. Scaling: Both give you tons of headroom before you need more than a single instance as a cache. Redis includes tools to help you go beyond that while memcached does not. 我们需要从以下4点来分析使用redis的优势 读写速度 内存使用 磁盘I/O dumping 缩放 memcachedMemcached is a simple volatile cache server. It allows you to store key/value pairs where the value is limited to being a string up to 1MB. It’s good at this, but that’s all it does. You can access those values by their key at extremely high speed, often saturating available network or even memory bandwidth. When you restart memcached your data is gone. This is fine for a cache. You shouldn’t store anything important there. If you need high performance or high availability there are 3rd party tools, products, and services available. redisRedis can do the same jobs as memcached can, and can do them better. Redis can act as a cache as well. It can store key/value pairs too. In redis they can even be up to 512MB. You can turn off persistence and it will happily lose your data on restart too. If you want your cache to survive restarts it lets you do that as well. In fact, that’s the default. It’s super fast too, often limited by network or memory bandwidth. If one instance of redis/memcached isn’t enough performance for your workload, redis is the clear choice. Redis includes cluster support and comes with high availability tools (redis-sentinel) right “in the box”. Over the past few years redis has also emerged as the clear leader in 3rd party tooling. Companies like Redis Labs, Amazon, and others offer many useful redis tools and services. The ecosystem around redis is much larger. The number of large scale deployments is now likely greater than for memcached. 从支持数据大小，速度，以及第三方支持来看两者的区别 The Redis SupersetRedis is more than a cache. It is an in-memory data structure server. Below you will find a quick overview of things Redis can do beyond being a simple key/value cache like memcached. Most of redis’ features are things memcached cannot do. Redis不仅仅作为一个cache来使用，他还是一个能够永久保存数据的NoSQL数据库 DocumentationRedis is better documented than memcached. While this can be subjective, it seems to be more and more true all the time. redis.io is a fantastic easily navigated resource. It lets you try redis in the browser and even gives you live interactive examples with each command in the docs. There are now 2x as many stackoverflow results for redis as memcached. 2x as many Google results. More readily accessible examples in more languages. More active development. More active client development. These measurements might not mean much individually, but in combination they paint a clear picture that support and documentation for redis is greater and much more up-to-date. Redis有着更丰富的文档支持 PersistenceBy default redis persists your data to disk using a mechanism called snapshotting. If you have enough RAM available it’s able to write all of your data to disk with almost no performance degradation. It’s almost free! In snapshot mode there is a chance that a sudden crash could result in a small amount of lost data. If you absolutely need to make sure no data is ever lost, don’t worry, redis has your back there too with AOF (Append Only File) mode. In this persistence mode data can be synced to disk as it is written. This can reduce maximum write throughput to however fast your disk can write, but should still be quite fast. There are many configuration options to fine tune persistence if you need, but the defaults are very sensible. These options make it easy to setup redis as a safe, redundant place to store data. It is a real database. Many Data TypesMemcached is limited to strings, but Redis is a data structure server that can serve up many different data types. It also provides the commands you need to make the most of those data types. Strings (commands)Simple text or binary values that can be up to 512MB in size. This is the only data type redis and memcached share, though memcached strings are limited to 1MB. Redis gives you more tools for leveraging this datatype by offering commands for bitwise operations, bit-level manipulation, floating point increment/decrement support, range queries, and multi-key operations. Memcached doesn’t support any of that. Strings are useful for all sorts of use cases, which is why memcached is fairly useful with this data type alone. Hashes (commands)Hashes are sort of like a key value store within a key value store. They map between string fields and string values. Field-&gt;value maps using a hash are slightly more space efficient than key-&gt;value maps using regular strings. Hashes are useful as a namespace, or when you want to logically group many keys. With a hash you can grab all the members efficiently, expire all the members together, delete all the members together, etc. Great for any use case where you have several key/value pairs that need to grouped. One example use of a hash is for storing user profiles between applications. A redis hash stored with the user ID as the key will allow you to store as many bits of data about a user as needed while keeping them stored under a single key. The advantage of using a hash instead of serializing the profile into a string is that you can have different applications read/write different fields within the user profile without having to worry about one app overriding changes made by others (which can happen if you serialize stale data). Lists (commands)Redis lists are ordered collections of strings. They are optimized for inserting, reading, or removing values from the top or bottom (aka: left or right) of the list. Redis provides many commands for leveraging lists, including commands to push/pop items, push/pop between lists, truncate lists, perform range queries, etc. Lists make great durable, atomic, queues. These work great for job queues, logs, buffers, and many other use cases. Sets (commands)Sets are unordered collections of unique values. They are optimized to let you quickly check if a value is in the set, quickly add/remove values, and to measure overlap with other sets. These are great for things like access control lists, unique visitor trackers, and many other things. Most programming languages have something similar (usually called a Set). This is like that, only distributed. Redis provides several commands to manage sets. Obvious ones like adding, removing, and checking the set are present. So are less obvious commands like popping/reading a random item and commands for performing unions and intersections with other sets. Sorted Sets (commands)Sorted Sets are also collections of unique values. These ones, as the name implies, are ordered. They are ordered by a score, then lexicographically. This data type is optimized for quick lookups by score. Getting the highest, lowest, or any range of values in between is extremely fast. If you add users to a sorted set along with their high score, you have yourself a perfect leader-board. As new high scores come in, just add them to the set again with their high score and it will re-order your leader-board. Also great for keeping track of the last time users visited and who is active in your application. Storing values with the same score causes them to be ordered lexicographically (think alphabetically). This can be useful for things like auto-complete features. Many of the sorted set commands are similar to commands for sets, sometimes with an additional score parameter. Also included are commands for managing scores and querying by score. Redis丰富的数据类型支持 Geo Redis has several commands for storing, retrieving, and measuring geographic data. This includes radius queries and measuring distances between points. Technically geographic data in redis is stored within sorted sets, so this isn’t a truly separate data type. It is more of an extension on top of sorted sets. Bitmap and HyperLogLogLike geo, these aren’t completely separate data types. These are commands that allow you to treat string data as if it’s either a bitmap or a hyperloglog. Bitmaps are what the bit-level operators I referenced under Strings are for. This data type was the basic building block for reddit’s recent collaborative art project: r/Place. HyperLogLog allows you to use a constant extremely small amount of space to count almost unlimited unique values with shocking accuracy. Using only ~16KB you could efficiently count the number of unique visitors to your site, even if that number is in the millions. Transactions and AtomicityCommands in redis are atomic, meaning you can be sure that as soon as you write a value to redis that value is visible to all clients connected to redis. There is no wait for that value to propagate. Technically memcached is atomic as well, but with redis adding all this functionality beyond memcached it is worth noting and somewhat impressive that all these additional data types and features are also atomic. While not quite the same as transactions in relational databases, redis also has transactions that use “optimistic locking” (WATCH/MULTI/EXEC). PipeliningRedis provides a feature called ‘pipelining’. If you have many redis commands you want to execute you can use pipelining to send them to redis all-at-once instead of one-at-a-time. Normally when you execute a command to either redis or memcached, each command is a separate request/response cycle. With pipelining, redis can buffer several commands and execute them all at once, responding with all of the responses to all of your commands in a single reply. This can allow you to achieve even greater throughput on bulk importing or other actions that involve lots of commands. Pub/SubRedis has commands dedicated to pub/sub functionality, allowing redis to act as a high speed message broadcaster. This allows a single client to publish messages to many other clients connected to a channel. Redis does pub/sub as well as almost any tool. Dedicated message brokers like RabbitMQ may have advantages in certain areas, but the fact that the same server can also give you persistent durable queues and other data structures your pub/sub workloads likely need, Redis will often prove to be the best and most simple tool for the job. Lua ScriptingYou can kind of think of lua scripts like redis’s own SQL or stored procedures. It’s both more and less than that, but the analogy mostly works. Maybe you have complex calculations you want redis to perform. Maybe you can’t afford to have your transactions roll back and need guarantees every step of a complex process will happen atomically. These problems and many more can be solved with lua scripting. The entire script is executed atomically, so if you can fit your logic into a lua script you can often avoid messing with optimistic locking transactions. ScalingAs mentioned above, redis includes built in support for clustering and is bundled with its own high availability tool called redis-sentinel. ConclusionWithout hesitation I would recommend redis over memcached for any new projects, or existing projects that don’t already use memcached. The above may sound like I don’t like memcached. On the contrary: it is a powerful, simple, stable, mature, and hardened tool. There are even some use cases where it’s a little faster than redis. I love memcached. I just don’t think it makes much sense for future development. Redis does everything memcached does, often better. Any performance advantage for memcached is minor and workload specific. There are also workloads for which redis will be faster, and many more workloads that redis can do which memcached simply can’t. The tiny performance differences seem minor in the face of the giant gulf in functionality and the fact that both tools are so fast and efficient they may very well be the last piece of your infrastructure you’ll ever have to worry about scaling. There is only one scenario where memcached makes more sense: where memcached is already in use as a cache. If you are already caching with memcached then keep using it, if it meets your needs. It is likely not worth the effort to move to redis and if you are going to use redis just for caching it may not offer enough benefit to be worth your time. If memcached isn’t meeting your needs, then you should probably move to redis. This is true whether you need to scale beyond memcached or you need additional functionality. 所感翻译无能啊，英文水平略显不足，还有就是专业纵深也不够，一些名词直接看不懂是什么意思，文章看到后半段的时候，脑子一片空白，虽然看得懂小半的意思，但是却不能理解具体的区别作用。 还有文章作者最后的一句话，I love memcached. I just don’t think it makes much sense for future development.莫名的让人有些难言的干涩，也摘下来共勉吧。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://zeco.oschina.io/categories/数据库/"},{"name":"nosql","slug":"数据库/nosql","permalink":"http://zeco.oschina.io/categories/数据库/nosql/"}],"tags":[{"name":"nosql","slug":"nosql","permalink":"http://zeco.oschina.io/tagcloud/nosql/"},{"name":"redis","slug":"redis","permalink":"http://zeco.oschina.io/tagcloud/redis/"},{"name":"memcached","slug":"memcached","permalink":"http://zeco.oschina.io/tagcloud/memcached/"}]},{"title":"PHP 性能分析与实验：性能的微观分析[转]","slug":"php_2","date":"un00fin00","updated":"un66fin66","comments":true,"path":"2016/10/16/php_2/","link":"","permalink":"http://zeco.oschina.io/2016/10/16/php_2/","excerpt":"在上一篇文章中，我们从 PHP 是解释性语言、动态语言和底层实现等三个方面，探讨了 PHP 性能的问题。本文就深入到 PHP 的微观层面，我们来了解 PHP 在使用和编写代码过程中，性能方面，可能需要注意和提升的地方。 在开始分析之前，我们得掌握一些与性能分析相关的函数。这些函数让我们对程序性能有更好的分析和评测。","text":"在上一篇文章中，我们从 PHP 是解释性语言、动态语言和底层实现等三个方面，探讨了 PHP 性能的问题。本文就深入到 PHP 的微观层面，我们来了解 PHP 在使用和编写代码过程中，性能方面，可能需要注意和提升的地方。 在开始分析之前，我们得掌握一些与性能分析相关的函数。这些函数让我们对程序性能有更好的分析和评测。 性能分析相关的函数与命令1.时间度量函数平时我们常用 time() 函数，但是返回的是秒数，对于某段代码的内部性能分析，到秒的精度是不够的。于是要用 microtime 函数。而 microtime 函数可以返回两种形式，一是字符串的形式，一是浮点数的形式。不过需要注意的是，在缺省的情况下，返回的精度只有4位小数。为了获得更高的精确度，我们需要配置 precision。 如下是 microtime 的使用结果:12345$start= microtime(true); echo $start.&quot;/n&quot;; $end = microtime(true); echo $end.&quot;/n&quot;; echo ($end-$start).&quot;/n&quot;; 输出为：1234bash-3.2# phptime.php 1441360050.3286 1441360050.3292 0.00053000450134277 而在代码前面加上一行：1ini_set(&quot;precision&quot;, 16); 输出为：1234bash-3.2# phptime.php 1441360210.932628 1441360210.932831 0.0002031326293945312 除了 microtime 内部统计之外， 还可以使用 getrusage 来取得用户态的时长。在实际的操作中，也常用 time 命令来计算整个程序的运行时长，通过多次运行或者修改代码后运行，得到不同的时间长度以得到效率上的区别。 具体用法是：time phptime.php ，则在程序运行完成之后，不管是否正常结束退出，都会有相关的统计。1234567bash-3.2# time phptime.php 1441360373.150756 1441360373.150959 0.0002031326293945312 real 0m0.186s user 0m0.072s sys 0m0.077s 因为本文所讨论的性能问题，往往分析上百万次调用之后的差距与趋势，为了避免代码中存在一些时间统计代码，后面我们使用 time 命令居多。 2.内存使用相关函数分析内存使用的函数有两个：memory get usage、memory get peak_usage，前者可以获得程序在调用的时间点，即当前所使用的内存，后者可以获得到目前为止高峰时期所使用的内存。所使用的内存以字节为单位。1234567 $base_memory= memory_get_usage(); echo &quot;Hello,world!/n&quot;; $end_memory= memory_get_usage(); $peak_memory= memory_get_peak_usage(); echo $base_memory,&quot;/t&quot;,$end_memory,&quot;/t&quot;,($end_memory-$base_memory),&quot;/t&quot;, $peak_memory,&quot;/n&quot;;``` 输出如下： bash-3.2# phphelloworld.php Hello,world! 224400 224568 168 227424 12可以看到，即使程序中间只输出了一句话，再加上变量存储，也消耗了168个字节的内存。对于同一程序，不同 PHP 版本对内存的使用并不相同，甚至还差别很大。 $baseMemory= memory_get_usage(); class User { private $uid; function __construct($uid) { $this-&gt;uid= $uid; } } for($i=0;$i&lt;100000;$i++) { $obj= new User($i); if ( $i% 10000 === 0 ) { echo sprintf( &apos;%6d: &apos;, $i), memory_get_usage(), &quot; bytes/n&quot;; } } echo &quot; peak: &quot;,memory_get_peak_usage(true), &quot; bytes/n&quot;; 12在 PHP 5.2 中，内存使用如下：` [root@localhostphpperf]# php52 memory.php 0: 93784 bytes 10000: 93784 bytes …… 80000: 93784 bytes 90000: 93784 bytes peak: 262144 bytes 1PHP 5.3 中，内存使用如下 [root@localhostphpperf]# phpmemory.php 0: 634992 bytes 10000: 634992 bytes …… 80000: 634992 bytes 90000: 634992 bytes peak: 786432 bytes 12可见 PHP 5.3 在内存使用上要粗放了一些。PHP 5.4 – 5.6 差不多，有所优化： [root@localhostphpperf]# php56 memory.php 0: 224944 bytes 10000: 224920 bytes …… 80000: 224920 bytes 90000: 224920 bytes peak: 262144 bytes 1而 PHP 7 在少量使用时，高峰内存的使用，增大很多。 [root@localhostphpperf]# php7 memory.php 0: 353912 bytes 10000: 353912 bytes …… 80000: 353912 bytes 90000: 353912 bytes peak: 2097152 bytes 12从上面也看到，以上所使用的 PHP 都有比较好的垃圾回收机制，10万次初始化,并没有随着对象初始化的增多而增加内存的使用。PHP7 的高峰内存使用最多，达到了接近 2M。下面再来看一个例子，在上面的代码的基础上，我们加上一行，如下： $obj-&gt;self = $obj; 1代码如下： $baseMemory= memory_get_usage(); class User { private $uid; function __construct($uid) { $this-&gt;uid= $uid; } } for($i=0;$i&lt;100000;$i++) { $obj= new User($i); $obj-&gt;self = $obj; if ( $i% 5000 === 0 ) { echo sprintf( &apos;%6d: &apos;, $i), memory_get_usage(), &quot; bytes/n&quot;; } } echo &quot; peak: &quot;,memory_get_peak_usage(true), &quot; bytes/n&quot;; 12345678910111213这时候再来看看内存的使用情况，中间表格主体部分为内存使用量，单位为字节。![](/css/images/php_2_1.jpg)图表如下：![](/css/images/php_2_2.jpg)PHP 5.2 并没有合适的垃圾回收机制，导致内存使用越来越多。而5.3 以后内存回收机制导致内存稳定在一个区间。而也可以看见 PHP7 内存使用最少。把 PHP 5.2 的图形去掉了之后，对比更为明显。![](/css/images/php_2_3.jpg)可见 PHP7 不仅是在算法效率上，有大幅度的提升，在大批量内存使用上也有大幅度的优化（尽管小程序的高峰内存比历史版本所用内存更多）。---#### 3.垃圾回收相关函数在 PHP 中，内存回收是可以控制的，我们可以显式地关闭或者打开垃圾回收，一种方法是通过修改配置，zend.enable_gc=Off 就可以关掉垃圾回收。 缺省情况下是 On 的。另外一种手段是通过 gc _enable()和gc _disable()函数分别打开和关闭垃圾回收。比如在上面的例子的基础上，我们关闭垃圾回收，就可以得到如下数据表格和图表。代码如下： gc_disable(); $baseMemory= memory_get_usage(); class User { private $uid; function __construct($uid) { $this-&gt;uid= $uid; } } for($i=0;$i&lt;100000;$i++) { $obj= new User($i); $obj-&gt;self = $obj; if ( $i% 5000 === 0 ) { echo sprintf( &apos;%6d: &apos;, $i), memory_get_usage(), &quot; bytes/n&quot;; } } echo &quot; peak: &quot;,memory_get_peak_usage(true), &quot; bytes/n&quot;; 1234567891011121314分别在 PHP 5.3、PHP5.4 、PHP5.5、PHP5.6 、PHP7 下运行，得到如下内存使用统计表。![](/css/images/php_2_4.jpg)图表如下，PHP7 还是内存使用效率最优的。![](/css/images/php_2_5.jpg)从上面的例子也可以看出来，尽管在第一个例子中，PHP7 的高峰内存使用数是最多的，但是当内存使用得多时，PHP7 的内存优化就体现出来了。这里值得一提的是垃圾回收，尽管会使内存减少，但是会导致速度降低，因为垃圾回收也是需要消耗 CPU 等其他系统资源的。Composer 项目就曾经因为在计算依赖前关闭垃圾回收，带来成倍性能提升，引发广大网友关注。详见：&lt;a href=&quot;https://github.com/composer/composer/commit/ac676f47f7bbc619678a29deae097b6b0710b799&quot;&gt;github&lt;/a&gt;在常见的代码和性能分析中，出了以上三类函数之外，还常使用的有堆栈跟踪函数、输出函数，这里不再赘述。---### PHP 性能分析10则下面我们根据小程序来验证一些常见的性能差别。#### 1.使用 echo 还是 print在有的建议规则中，会建议使用 echo ，而不使用 print。说 print 是函数，而 echo 是语法结构。实际上并不是如此，print 也是语法结构，类似的语法结构，还有多个，比如 list、isset、require 等。不过对于 PHP 7 以下 PHP 版本而言，两者确实有性能上的差别。如下两份代码： for($i=0; $i&lt;1000000; $i++) { echo(&quot;Hello,World!&quot;); } for($i=0; $i&lt;1000000; $i++) { print (&quot;Hello,World!&quot;); } 1在 PHP 5.3 中运行速度分别如下（各2次）： [root@localhostphpperf]# time php echo1.php &gt; /dev/null real 0m0.233s user 0m0.153s sys 0m0.080s [root@localhostphpperf]# time php echo1.php &gt; /dev/null real 0m0.234s user 0m0.159s sys 0m0.073s [root@localhostphpperf]# time phpecho.php&gt; /dev/null real 0m0.203s user 0m0.130s sys 0m0.072s [root@localhostphpperf]# time phpecho.php&gt; /dev/null real 0m0.203s user 0m0.128s sys 0m0.075s 1在 PHP5.3 版中效率差距10%以上。而在 PHP5.4 以上的版本中，区别不大，如下是 PHP7 中的运行效率。 [root@localhostphpperf]# time php7 echo.php&gt; /dev/null real 0m0.151s user 0m0.088s sys 0m0.062s [root@localhostphpperf]# time php7 echo.php&gt; /dev/null real 0m0.145s user 0m0.084s sys 0m0.061s [root@localhostphpperf]# time php7 echo1.php &gt; /dev/null real 0m0.140s user 0m0.075s sys 0m0.064s [root@localhostphpperf]# time php7 echo1.php &gt; /dev/null real 0m0.146s user 0m0.077s sys 0m0.069s 123456正如浏览器前端的一些优化准则一样，没有啥特别通用的原则，往往根据不同的情况和版本，规则也会存在不同。---#### 2.require 还是 require_once？在一些常规的优化规则中，会提到，建议使用 require_ once 而不是 require，现由是 require_ once 会去检测是否重复，而 require 则不需要重复检测。在大量不同文件的包含中，require_ once 略慢于 require。但是 require_ once 的检测是一项内存中的行为，也就是说即使有数个需要加载的文件，检测也只是内存中的比较。而 require 的每次重新加载，都会从文件系统中去读取分析。因而 require_ once 会比 require 更佳。咱们也使用一个例子来看一下。 str.php global$str; $str= &quot;China has a large population&quot;; require.php for($i=0; $i&lt;100000; $i++) { require &quot;str.php&quot;; } require_once.php for($i=0; $i&lt;100000; $i++) { require_once&quot;str.php&quot;; } 1上面的例子，在 PHP7 中，require_ once.php 的运行速度是 require.php 的30倍！在其他版本也能得到大致相同的结果。 [root@localhostphpperf]# time php7 require.php real 0m1.712s user 0m1.126s sys 0m0.569s [root@localhostphpperf]# time php7 require.php real 0m1.640s user 0m1.113s sys 0m0.515s [root@localhostphpperf]# time php7 require_once.php real 0m0.066s user 0m0.063s sys 0m0.003s [root@localhostphpperf]# time php7 require_once.php real 0m0.057s user 0m0.052s sys 0m0.004s 12345从上可以看到，如果存在大量的重复加载的话，require_ once 明显优于 require，因为重复的文件不再有 IO 操作。即使不是大量重复的加载，也建议使用 require_ once，因为在一个程序中，一般不会存在数以千百计的文件包含，100次内存比较的速度差距，一个文件包含就相当了。---#### 3.单引号还是双引号？单引号，还是双引号，是一个问题。一般的建议是能使用单引号的地方，就不要使用双引号，因为字符串中的单引号，不会引起解析，从而效率更高。那来看一下实际的差别。 classUser { private $uid; private $username; private $age; function __construct($uid, $username,$age){ $this-&gt;uid= $uid; $this-&gt;username = $username; $this-&gt;age = $age; } function getUserInfo() { return &quot;UID:&quot;.$this-&gt;uid.&quot; UserName:&quot;.$this-&gt;username.&quot; Age:&quot;.$this-&gt;age; } function getUserInfoSingle() { return &apos;UID:&apos;.$this-&gt;uid.&apos; UserName:&apos;.$this-&gt;username.&apos; Age&apos;.$this-&gt;age; } function getUserInfoOnce() { return &quot;UID:{$this-&gt;uid}UserName:{$this-&gt;username} Age:{$this-&gt;age}&quot;; } function getUserInfoSingle2() { return &apos;UID:{$this-&gt;uid} UserName:{$this-&gt;username} Age:{$this-&gt;age}&apos;; } } for($i=0; $i&lt;1000000;$i++) { $user = new User($i, &quot;name&quot;.$i, $i%100); $user-&gt;getUserInfoSingle(); } 123在上面的 User 类中，有四个不同的方法,完成一样的功能，就是拼接信息返回，看看这四个不同的方法的区别。##### 1.getUserInfo 使用双引号和属性相拼接 [root@localhostphpperf]# time php7 string.php real 0m0.670s user 0m0.665s sys 0m0.002s [root@localhostphpperf]# time php7 string.php real 0m0.692s user 0m0.689s sys 0m0.002s [root@localhostphpperf]# time php7 string.php real 0m0.683s user 0m0.672s sys 0m0.004s 12##### 2.getUserInfoSingle 使用单引号和属性相拼接 [root@localhostphpperf]# time php7 string.php real 0m0.686s user 0m0.683s sys 0m0.001s [root@localhostphpperf]# time php7 string.php real 0m0.671s user 0m0.666s sys 0m0.003s [root@localhostphpperf]# time php7 string.php real 0m0.669s user 0m0.666s sys 0m0.002s 123可见在拼接中，单双引号并无明显差别。##### 3.getUserInfoOnce不再使用句号.连接，而是直接引入在字符串中解析。 [root@localhostphpperf]# time php7 string.php real 0m0.564s user 0m0.556s sys 0m0.006s [root@localhostphpperf]# time php7 string.php real 0m0.592s user 0m0.587s sys 0m0.004s [root@localhostphpperf]# time php7 string.php real 0m0.563s user 0m0.559s sys 0m0.003s 123从上面可见，速度提高了0.06s-0.10s，有10%-20%的效率提升。可见连缀效率更低一些。##### 4.getUserInfoSingle2 虽然没有达到我们真正想要的效果，功能是不正确的，但是在字符串中，不再需要解析变量和获取变量值，所以效率确实有大幅度提升。 [root@localhostphpperf]# time php7 string.php real 0m0.379s user 0m0.375s sys 0m0.003s [root@localhostphpperf]# time php7 string.php real 0m0.399s user 0m0.394s sys 0m0.003s [root@localhostphpperf]# time php7 string.php real 0m0.377s user 0m0.371s sys 0m0.004s 12效率确实有了大的提升，快了50%。那么这个快，是由于不需要变量引用解析带来的，还是只要加入$天然的呢？我们再试着写了一个方法。 functiongetUserInfoSingle3() { return &quot;UID:{\\$this-&gt;uid} UserName:{\\$this-&gt;username} Age:{\\$this-&gt;age}&quot;; } 1得到如下运行时间： [root@localhostphpperf]# time php7 string.php real 0m0.385s user 0m0.381s sys 0m0.002s [root@localhostphpperf]# time php7 string.php real 0m0.382s user 0m0.380s sys 0m0.002s [root@localhostphpperf]# time php7 string.php real 0m0.386s user 0m0.380s sys 0m0.004s 12345发现转义后的字符串，效率跟单引号是一致的，从这里也可以看见，单引号还是双引号包含，如果不存在需要解析的变量，几乎没有差别。如果有需要解析的变量，你也不能光用单引号，要么使用单引号和连缀，要么使用内部插值，所以在这条规则上，不用太过纠结。---#### 4.错误应该打开还是关闭？在 PHP 中，有多种错误消息，错误消息的开启是否会带来性能上的影响呢？从直觉觉得，由于错误消息，本身会涉及到 IO 输出，无论是输出到终端或者 error_log，都是如此，所以肯定会影响性能。我们来看看这个影响有多大。 error_reporting(E_ERROR); for($i=0; $i&lt;1000000;$i++) { $str= &quot;通常，$PHP中的垃圾回收机制，仅仅在循环回收算法确实运行时会有时间消耗上的增加。但是在平常的(更小的)脚本中应根本就没有性能影响。 然而，在平常脚本中有循环回收机制运行的情况下，内存的节省将允许更多这种脚本同时运行在你的服务器上。因为总共使用的内存没达到上限。&quot;; } 1234在上面的代码中，我们涉及到一个不存在的变量，所以会报出 Notice 错误:Notice: Undefined variable: PHP 中的垃圾回收机制，仅仅在循环回收算法确实运行时会有时间消耗上的增加。但是在平常的 in xxxx/string2.php on line 10如果把 E_ ERROR 改成 E_ ALL 就能看到大量的上述错误输出。我们先执行 E_ ERROR 版，这个时候没有任何错误日志输出。得到如下数据： [root@localhostphpperf]# time php7 string2.php real 0m0.442s user 0m0.434s sys 0m0.005s [root@localhostphpperf]# time php7 string2.php real 0m0.487s user 0m0.484s sys 0m0.002s [root@localhostphpperf]# time php7 string2.php real 0m0.476s user 0m0.471s sys 0m0.003s 1再执行 E_ ALL 版，有大量的错误日志输出，我们把输出重定向到/dev/null [root@localhostphpperf]# time php7 string2.php &gt; /dev/null real 0m0.928s user 0m0.873s sys 0m0.051s [root@localhostphpperf]# time php7 string2.php &gt; /dev/null real 0m0.984s user 0m0.917s sys 0m0.064s [root@localhostphpperf]# time php7 string2.php &gt; /dev/null real 0m0.945s user 0m0.887s sys 0m0.056s 12345可见慢了将近一倍。如上可见，即使输出没有正式写入文件，错误级别打开的影响也是巨大的。在线上我们应该将错误级别调到 E_ ERROR 这个级别，同时将错误写入 error_ log，既减少了不必要的错误信息输出，又避免泄漏路径等信息，造成安全隐患。#### 5.正则表达式和普通字符串操作在字符串操作中，有一条常见的规则，即是能使用普通字符串操作方法替代的，就不要使用正则表达式来处理，用 C 语言操作 PCRE 做过正则表达式处理的童鞋应该清楚，需要先 compile，再 exec，也就是说是一个相对复杂的过程。现在就比较一下两者的差别。对于简单的分隔，我们可以使用 explode 来实现，也可以使用正则表达式，比如下面的例子： ini_set(&quot;precision&quot;, 16); function microtime_ex() { list($usec, $sec) = explode(&quot; &quot;, microtime()); return $sec+$usec; } for($i=0; $i&lt;1000000; $i++) { microtime_ex(); } 1耗时在0.93-1S之间。 [root@localhostphpperf]# time php7 pregstring.php real 0m0.941s user 0m0.931s sys 0m0.007s [root@localhostphpperf]# time php7 pregstring.php real 0m0.986s user 0m0.980s sys 0m0.004s [root@localhostphpperf]# time php7 pregstring.php real 0m1.004s user 0m0.998s sys 0m0.003s 1我们再将分隔语句替换成： list($usec, $sec) = preg_split(&quot;#\\s#&quot;, microtime()); 1得到如下数据，慢了近10-20%。 [root@localhostphpperf]# time php7 pregstring1.php real 0m1.195s user 0m1.182s sys 0m0.004s [root@localhostphpperf]# time php7 pregstring1.php real 0m1.222s user 0m1.217s sys 0m0.003s [root@localhostphpperf]# time php7 pregstring1.php real 0m1.101s user 0m1.091s sys 0m0.005s 1再将语句替换成： list($usec, $sec) = preg_split(&quot;#\\s+#&quot;, microtime()); 12即匹配一到多个空格，并没有太多的影响。除了分隔外，查找我们也来看一个例子。第一段代码： $str= &quot;China has a Large population&quot;; for($i=0; $i&lt;1000000; $i++) { if(preg_match(&quot;#l#i&quot;, $str)) { } } 1第二段代码： $str= &quot;China has a large population&quot;; for($i=0; $i&lt;1000000; $i++) { if(stripos($str, &quot;l&quot;)!==false) { } } 12这两段代码达到的效果相同，都是查找字符串中有无 l 或者 L 字符。在 PHP 7 下运行效果如下： [root@localhostphpperf]# time php7 pregstring2.php real 0m0.172s user 0m0.167s sys 0m0.003s [root@localhostphpperf]# time php7 pregstring2.php real 0m0.199s user 0m0.196s sys 0m0.002s [root@localhostphpperf]# time php7 pregstring3.php real 0m0.185s user 0m0.182s sys 0m0.003s [root@localhostphpperf]# time php7 pregstring3.php real 0m0.184s user 0m0.181s sys 0m0.003s 1两者区别不大。再看看在 PHP5.6 中的表现。 [root@localhostphpperf]# time php56 pregstring2.php real 0m0.470s user 0m0.456s sys 0m0.004s [root@localhostphpperf]# time php56 pregstring2.php real 0m0.506s user 0m0.500s sys 0m0.005s [root@localhostphpperf]# time php56 pregstring3.php real 0m0.348s user 0m0.342s sys 0m0.004s [root@localhostphpperf]# time php56 pregstring3.php real 0m0.376s user 0m0.364s sys 0m0.003s 1可见在 PHP 5.6 中表现还是非常明显的，使用正则表达式慢了20%。PHP7 难道是对已使用过的正则表达式做了缓存？我们调整一下代码如下： $str= &quot;China has a Large population&quot;; for($i=0; $i&lt;1000000; $i++) { $pattern = &quot;#&quot;.chr(ord(&apos;a&apos;)+$i%26).&quot;#i&quot;; if($ret = preg_match($pattern, $str)!==false) { } } 1这是一个动态编译的 pattern。 $str= &quot;China has a large population&quot;; for($i=0; $i&lt;1000000; $i++) { $pattern = &quot;&quot;.chr(ord(&apos;a&apos;)+$i%26).&quot;&quot;; if($ret = stripos($str, $pattern)!==false) { } } 1在 PHP7 中，得到了如下结果： [root@localhostphpperf]# time php7 pregstring2.php real 0m0.351s user 0m0.346s sys 0m0.004s [root@localhostphpperf]# time php7 pregstring2.php real 0m0.359s user 0m0.352s sys 0m0.004s [root@localhostphpperf]# time php7 pregstring3.php real 0m0.375s user 0m0.369s sys 0m0.003s [root@localhostphpperf]# time php7 pregstring3.php real 0m0.370s user 0m0.365s sys 0m0.005s 1可见两者并不明显。而在 PHP 5.6 中，同样的代码： [root@localhostphpperf]# time php56 pregstring2.php real 0m1.022s user 0m1.015s sys 0m0.005s [root@localhostphpperf]# time php56 pregstring2.php real 0m1.049s user 0m1.041s sys 0m0.005s [root@localhostphpperf]# time php56 pregstring3.php real 0m0.923s user 0m0.821s sys 0m0.002s [root@localhostphpperf]# time php56 pregstring3.php real 0m0.838s user 0m0.831s sys 0m0.004s 123456789101112在 PHP 5.6 中，stripos 版明显要快于正则表达式版，由上两例可见，PHP7对正则表达式的优化还是相当惊人的。其次也建议，能用普通字符串操作的地方，可以避免使用正则表达式。 因为在其他版本中，这个规则还是适用的。某 zend 大牛官方的分享给出如下数据：&gt;stripos(‘http://’, $website) 速度是preg_match(‘/http:\\/\\//i’, $website) 的两倍&gt;ctype_alnum()速度是preg_match(‘/^\\s*$/’)的5倍;“if ($test == (int)$test)” 比 preg_match(‘/^\\d*$/’)快5倍可以相见，正则表达式是相对低效的。---#### 6.数组元素定位查找在数组元素的查找中，有一个关键的注意点就是数组值和键的查找速度，差异非常大。了解过 PHP 扩展开发的朋友，应该清楚，数组在底层其实是 Hash 表。所以键是以快速定位的，而值却未必。下面来看例子。首先们构造一个数组： $a= array(); for($i=0;$i&lt;100000;$i++){ $a[$i] = $i; } 12在这个数组中，我们测试查找值和查找键的效率差别。第一种方法用 array_ search，第二种用 array_ key_ exists，第三种用 isset 语法结构。 代码分别如下： //查找值 foreach($a as $i) { array_search($i, $a); } //查找键 foreach($a as $i) { array_key_exists($i, $a); } //判定键是否存在 foreach($a as $i) { if(isset($a[$i])); } 1运行结果如下： [root@localhostphpperf]# time php7 array.php real 0m9.026s user 0m8.965s sys 0m0.007s [root@localhostphpperf]# time php7 array.php real 0m9.063s user 0m8.965s sys 0m0.005s [root@localhostphpperf]# time php7 array1.php real 0m0.018s user 0m0.016s sys 0m0.001s [root@localhostphpperf]# time php7 array1.php real 0m0.021s user 0m0.015s sys 0m0.004s [root@localhostphpperf]# time php7 array2.php real 0m0.020s user 0m0.014s sys 0m0.006s [root@localhostphpperf]# time php7 array2.php real 0m0.016s user 0m0.009s sys 0m0.006s 1234由上例子可见，键值查找的速度比值查找的速度有百倍以上的效率差别。因而如果能用键值定位的地方，尽量用键值定位，而不是值查找。#### 7.对象与数组在 PHP 中，数组就是字典，字典可以存储属性和属性值，而且无论是键还是值，都不要求数据类型统一，所以对象数据存储，既能用对象数据结构的属性存储数据，也能使用数组的元素存储数据。那么两者有何差别呢？使用对象： classUser { public $uid; public $username; public $age; function getUserInfo() { return &quot;UID:&quot;.$this-&gt;uid.&quot; UserName:&quot;.$this-&gt;username.&quot; Age:&quot;.$this-&gt;age; } } for($i=0; $i&lt;1000000;$i++) { $user = new User(); $user-&gt;uid= $i; $user-&gt;age = $i%100; $user-&gt;username=&quot;User&quot;.$i; $user-&gt;getUserInfo(); } 1使用数组： functiongetUserInfo($user) { return &quot;UID:&quot;.$user[&apos;uid&apos;].&quot; UserName:&quot;.$user[&apos;username&apos;].&quot; Age:&quot;.$user[&apos;age&apos;]; } for($i=0; $i&lt;1000000;$i++) { $user = array(&quot;uid&quot;=&gt;$i,&quot;age&quot; =&gt;$i%100,&quot;username&quot;=&gt;&quot;User&quot;.$i); getUserInfo($user); } 1我们分别在 PHP5.3、PHP 5.6 和 PHP 7 中运行这两段代码。 [root@localhostphpperf]# time phpobject.php real 0m2.144s user 0m2.119s sys 0m0.009s [root@localhostphpperf]# time phpobject.php real 0m2.106s user 0m2.089s sys 0m0.013s [root@localhostphpperf]# time php object1.php real 0m1.421s user 0m1.402s sys 0m0.016s [root@localhostphpperf]# time php object1.php real 0m1.431s user 0m1.410s sys 0m0.012s 1在 PHP 5.3 中，数组版比对象版快了近30%。 [root@localhostphpperf]# time php56 object.php real 0m1.323s user 0m1.319s sys 0m0.002s [root@localhostphpperf]# time php56 object.php real 0m1.414s user 0m1.400s sys 0m0.006s [root@localhostphpperf]# time php56 object1.php real 0m1.356s user 0m1.352s sys 0m0.002s [root@localhostphpperf]# time php56 object1.php real 0m1.364s user 0m1.349s sys 0m0.006s [root@localhostphpperf]# time php7 object.php real 0m0.642s user 0m0.638s sys 0m0.003s [root@localhostphpperf]# time php7 object.php real 0m0.606s user 0m0.602s sys 0m0.003s [root@localhostphpperf]# time php7 object1.php real 0m0.615s user 0m0.613s sys 0m0.000s [root@localhostphpperf]# time php7 object1.php real 0m0.615s user 0m0.611s sys 0m0.003s 123456到了 PHP 5.6 和 PHP7 中，两个版本基本没有差别，而在 PHP7 中的速度是 PHP5.6 中的2倍。在新的版本中，差别已几乎没有，那么为了清楚起见我们当然应该声明类，实例化类来存储对象数据。---#### 8.getter 和 setter从 Java 转过来学习 PHP 的朋友，在对象声明时，可能习惯使用 getter 和 setter，那么，在 PHP 中，使用 getter 和 setter 是否会带来性能上的损失呢？同样，先上例子。无 setter版： classUser { public $uid; public $username; public $age; function getUserInfo() { return &quot;UID:&quot;.$this-&gt;uid.&quot; UserName:&quot;.$this-&gt;username.&quot; Age:&quot;.$this-&gt;age; } } for($i=0; $i&lt;1000000;$i++) { $user = new User(); $user-&gt;uid= $i; $user-&gt;age = $i%100; $user-&gt;username=&quot;User&quot;.$i; $user-&gt;getUserInfo(); } 1有 setter版： classUser { public $uid; private $username; public $age; function setUserName($name) { $this-&gt;username = $name; } function getUserInfo() { return &quot;UID:&quot;.$this-&gt;uid.&quot; UserName:&quot;.$this-&gt;username.&quot; Age:&quot;.$this-&gt;age; } } for($i=0; $i&lt;1000000;$i++) { $user = new User(); $user-&gt;uid= $i; $user-&gt;age = $i%100; $user-&gt;setUserName(&quot;User&quot;.$i); $user-&gt;getUserInfo(); } 1这里只增加了一个 setter。运行结果如下： [root@localhostphpperf]# time php7 object.php real 0m0.607s user 0m0.602s sys 0m0.004s [root@localhostphpperf]# time php7 object.php real 0m0.598s user 0m0.596s sys 0m0.000s [root@localhostphpperf]# time php7 object2.php real 0m0.673s user 0m0.669s sys 0m0.003s [root@localhostphpperf]# time php7 object2.php real 0m0.668s user 0m0.664s sys 0m0.004s 123456从上面可以看到，增加了一个 setter，带来了近10%的效率损失。可见这个性能损失是相当大的，在 PHP 中，我们没有必要再来做 setter 和 getter了。需要引用的属性，直接使用即可。---#### 9.类属性该声明还是不声明PHP 本身支持属性可以在使用时增加，也就是不声明属性，可以在运行时添加属性。那么问题来了，事先声明属性与事后增加属性，是否会有性能上的差别。这里也举一个例子探讨一下。事先声明了属性的代码就是2.8节中，无 setter 的代码，不再重复。而无属性声明的代码如下： classUser { function getUserInfo() { return &quot;UID:&quot;.$this-&gt;uid.&quot; UserName:&quot;.$this-&gt;username.&quot; Age:&quot;.$this-&gt;age; } } for($i=0; $i&lt;1000000;$i++) { $user = new User(); $user-&gt;uid= $i; $user-&gt;age = $i%100; $user-&gt;username=&quot;User&quot;.$i; $user-&gt;getUserInfo(); } 1两段代码，运行结果如下： [root@localhostphpperf]# time php7 object.php real 0m0.608s user 0m0.604s sys 0m0.003s [root@localhostphpperf]# time php7 object.php real 0m0.615s user 0m0.605s sys 0m0.003s [root@localhostphpperf]# time php7 object3.php real 0m0.733s user 0m0.728s sys 0m0.004s [root@localhostphpperf]# time php7 object3.php real 0m0.727s user 0m0.720s sys 0m0.004s 123456从上面的运行可以看到，无属性声明的代码慢了20%。可以推断出来的就是对于对象的属性，如果事先知道的话，我们还是事先声明的好，这一方面是效率问题，另一方面，也有助于提高代码的可读性呢。---#### 10.图片操作 API 的效率差别在图片处理操作中，一个非常常见的操作是将图片缩放成小图。缩放成小图的办法有多种，有使用 API 的，有使用命令行的。在 PHP 中，有 iMagick 和 gmagick 两个扩展可供操作，而命令行则一般使用 convert 命令来处理。我们这里来讨论使用 imagick 扩展中的 API 处理图片的效率差别。先上代码： function imagick_resize($filename, $outname) { $thumbnail = new Imagick($filename); $thumbnail-&gt;resizeImage(200, 200, imagick::FILTER_LANCZOS, 1); $thumbnail-&gt;writeImage($outname); unset($thumbnail); } function imagick_scale($filename, $outname) { $thumbnail = new Imagick($filename); $thumbnail-&gt;scaleImage(200, 200); $thumbnail-&gt;writeImage($outname); unset($thumbnail); } function convert($func) { $cmd= &quot;find /var/data/ppt |grep jpg&quot;; $start = microtime(true); exec($cmd, $files); $index = 0; foreach($files as $key =&gt;$filename) { $outname= &quot; /tmp/$func&quot;.&quot;_&quot;.&quot;$key.jpg&quot;; $func($filename, $outname); $index++; } $end = microtime(true); echo &quot;$func $index files: &quot; . ($end- $start) . &quot;s\\n&quot;; } convert(&quot;imagick_resize&quot;); convert(&quot;imagick_scale&quot;); 1在上面的代码中，我们分别使用了 resizeImage 和 scaleImage 来进行图片的压缩，压缩的是常见的 1-3M 之间的数码相机图片，得到如下运行结果： [root@localhostphpperf]# php55 imagick.php imagick_ resize 169 files: 5.0612308979034s imagick_ scale 169 files: 3.1105840206146s [root@localhostphpperf]# php55 imagick.php imagick_ resize 169 files: 4.4953861236572s imagick_ scale 169 files: 3.1514940261841s [root@localhostphpperf]# php55 imagick.php imagick_ resize 169 files: 4.5400381088257s imagick_ scale 169 files: 3.2625908851624s ```169张图片压缩，使用 resizeImage 压缩，速度在4.5S以上，而使用 scaleImage 则在 3.2S 左右，快了将近50%，压缩的效果，用肉眼看不出明显区别。当然 resizeImage 的控制能力更强，不过对于批量处理而言，使用 scaleImage 是更好的选择，尤其对头像压缩这种频繁大量的操作。本节只是例举了图片压缩 API 作为例子，也正像 explode 和 preg_ split 一样，在 PHP 中，完成同样一件事情，往往有多种手法。建议采用效率高的做法。 以上就是关于 PHP 开发的10个方面的对比，这些点涉及到 PHP 语法、写法以及 API 的使用。有些策略随着 PHP 的发展，有的已经不再适用，有些策略则会一直有用。 有童鞋也许会说，在现实的开发应用中，上面的某些观点和解决策略，有点「然并卵」。为什么这么说呢？因为在一个程序的性能瓶颈中，最为核心的瓶颈， 往往并不在 PHP 语言本身。即使是跟 PHP 代码中暴露出来的性能瓶颈，也常在外部资源和程序的不良写法导致的瓶颈上。于是为了做好性能分析，我们需要向 PHP 的上下游戏延伸，比如延伸到后端的服务上去，比如延伸到前端的优化规则。在这两块，都有了相当多的积累和分析，雅虎也据此提出了多达35条前端优化规则， 这些同 PHP 本身的性能分析构成了一个整体，就是降低用户的访问延时。 所以前面两部分所述的性能分析，只是有助于大家了解 PHP 开发本身，写出更好的 PHP 程序，为你成为一个资深的 PHP 程序员打下基础，对于实际生产中程序的效率提升，往往帮助也不是特别显著，因为大家也看到，在文章的实例中，很多操作往往是百万次才能看出明显的性能差别。在现实的页面中，每一个请求很快执行完成，对这些基础代码的调用，往往不会有这么多次调用。不过了解这些，总是好的。 那么，对于一个程序而言，其他的性能瓶颈可能存在哪里？我们将深入探讨。所以在本系列的下两篇，我们将探讨 PHP 程序的外围效源的效率问题和前端效率问题，敬请期待。","categories":[{"name":"php","slug":"php","permalink":"http://zeco.oschina.io/categories/php/"},{"name":"底层","slug":"php/底层","permalink":"http://zeco.oschina.io/categories/php/底层/"}],"tags":[{"name":"php","slug":"php","permalink":"http://zeco.oschina.io/tagcloud/php/"},{"name":"底层性能","slug":"底层性能","permalink":"http://zeco.oschina.io/tagcloud/底层性能/"}]},{"title":"PHP 性能分析与实验：性能的宏观分析[转]","slug":"php_1","date":"un33fin33","updated":"un66fin66","comments":true,"path":"2016/10/05/php_1/","link":"","permalink":"http://zeco.oschina.io/2016/10/05/php_1/","excerpt":"对 PHP 性能的分析，我们从两个层面着手，把这篇文章也分成了两个部分，一个是宏观层面，所谓宏观层面，就是 PHP 语言本身和环境层面，一个是应用层面，就是语法和使用规则的层面，不过不仅探讨规则，更辅助以示例的分析。 宏观层面，也就是对 PHP 语言本身的性能分析又分为三个方面： PHP 作为解释性语言性能有其天然的缺陷 PHP 作为动态类型语言在性能上也有提升的空间 当下主流 PHP 版本本身语言引擎性能","text":"对 PHP 性能的分析，我们从两个层面着手，把这篇文章也分成了两个部分，一个是宏观层面，所谓宏观层面，就是 PHP 语言本身和环境层面，一个是应用层面，就是语法和使用规则的层面，不过不仅探讨规则，更辅助以示例的分析。 宏观层面，也就是对 PHP 语言本身的性能分析又分为三个方面： PHP 作为解释性语言性能有其天然的缺陷 PHP 作为动态类型语言在性能上也有提升的空间 当下主流 PHP 版本本身语言引擎性能 PHP 作为解释性语言的性能分析与提升PHP 作为一门脚本语言，也是解释性语言，是其天然性能受限的原因，因为同编译型语言在运行之前编译成二进制代码不同，解释性语言在每一次运行都面对原始脚本的输入、解析、编译，然后执行。如下是 PHP 作为解释性语言的执行过程。如上所示，从上图可以看到，每一次运行，都需要经历三个解析、编译、运行三个过程。 那优化的点在哪里呢？可以想见，只要代码文件确定，解析到编译这一步都是确定的，因为文件已不再变化，而执行，则由于输入参数的不同而不同。在性能优化的世界里，至上绝招就是在获得同样结果的情况下，减少操作，这就是大名鼎鼎的缓存。缓存无处不在，缓存也是性能优化的杀手锏。于是乎 OpCode 缓存这一招就出现了，只有第一次需要解析和编译，而在后面的执行中，直接由脚本到 Opcode，从而实现了性能提速。执行流程如下图所示：相对每一次解析、编译，读到脚本之后，直接从缓存读取字节码的效率会有大幅度的提升，提升幅度到底有多大呢？ 我们来做一个没有 Opcode 缓存的实验。20 个并发，总共 10000 次请求没有经过 opcode 缓存的请求，，得到如下结果：其次，我们在服务器上打开 Opcode 缓存。要想实现 opcode 缓存，只需要安装 APC、Zend OPCache、eAccelerator 扩展即可，即使安装了多个，也只启用其中一个。注意的是，修改了 php.ini 配置之后，需要重新加载 php-fpm 的配置。 这里分别启用 APC 和 Zend OPCache 做实验。启用 APC 的版本。从上面的这个实验可以看到，所用的测试页面，有 40ms 以上的时间花在了语法解析和编译这两项上。通过将这两个操作缓存，可以将这个处理过程的速度大大提升。 这里附加补充一下，OpCode 到底是什么东东，OpCode 编译之后的字节码，我们可以使用bytekit 这样的工具，或者使用 vld PHP 扩展来实现对 PHP 的代码编译。如下是 vld 插件解析代码的运行结果。可以看到每一行代码被编译成相应的 OpCode 的输出。 第二个是 PHP 语言是动态类型的语言，动态类型的语言本身由于涉及到在内存中的类型推断，比如在 PHP 中，两个整数相加，我们能得到整数值，一个整数和一个字符串相加，甚至两个字符串相加，都变成整数相加。而字符串和任何类型连接操作都成了字符串。1234567&lt;?php$a = 10.11;$b = &quot;30&quot;;var_dump($a+$b);var_dump(&quot;10&quot;+$b);var_dump(10+&quot;20&quot;);var_dump(&quot;10&quot;+&quot;20&quot;); 运行结果如下：1234float(40.11)int(40)int(30)int(30) 语言的动态类型为开发者提供了方便，语言本身则会因为动态类型而降低效率。在 Swift 中，有一个特性叫类型推断，我们可以看看类型推断会带来多大的一个效率上的差别呢？对于需要类型推断与不需要类型推断两段 Swift 代码，我们尝试编译一下看看效果如何。 第一段代码如下：这是一段 Swift 代码，字典只有 14 个键值对，这段代码的编译，9 分钟了还没有编译完成（5G 内存，2.4GHz CPU），编译环境为 Swift 1.2，Xcode 6.4。但是如果调整代码如下：也就是加上了类型限定，避免了 planeLocation 的类型推断。编译过程花了 2S 。可见，作为动态类型附加的类型推断操作极大地降低了程序的编译速度。 当然，这个例子有点极端，用 Swift 来类比 PHP 也不一定合适，因为 Swift 语言本身也还在不断的进化过程中。本例子只是表明在编程语言中，如果是动态类型语言，就涉及到对动态类型的处理，从编译的角度讲是会受影响的。 那么作为动态类型的 PHP 的效率如何提升呢？从 PHP 语言本身这个层面是没有办法解决的，因为你怎么写也是动态类型的代码。解决办法就是将PHP转化为静态类型的表示，也就是做成扩展，可以看到，鸟哥的很多项目，比如 Yaf 框架，都是做成了扩展的，当然这也是由于鸟哥是 C 高手。扩展由于是 C 或者 C++ 而写，所以不再是动态类型，又加之是编译好的，而 C 语言本身的效率也会提升很多。所以效率会大幅度提高。 下面我们来看一段代码，这段代码，只是实现了简单的素数运算，能计算指定值以内的素数个数，用的是普通的筛选法。现在看看扩展实现，跟 PHP 原生实现的效率差别，这个差别当然，不仅仅是动态类型和编译类型的差别，还有语言效率的差别。 首先是用纯 PHP 写成的算法，计算 1000 万以内的素数个数，耗时在 33s 上下，实验了三次，得到的结果基本相同。其次，我们将这个求素数个数的过程，编写成了 PHP 扩展，在扩展中实现了 getprimenumbers 函数，输入一个整数，返回小于该整数的素数。得到的结果如下，这个效率的提升是非常惊人的，在 1.4s 上下即返回。速度提升 20 倍以上。可以想见，静态和编译类型的语言，其效率得到了惊人的提升。本程序的 C 语言代码如下：12345678910111213141516171819202122232425262728293031323334353637383940PHP_FUNCTION(get_prime_numbers)&#123; long value; if (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, &quot;l&quot;, &amp;value) == FAILURE) &#123; return; &#125; int *numbers = (int *)malloc(sizeof(int)*128*10000); memset(numbers, 0x0, 128*10000); int num = 2; numbers[0] = 2; numbers[1] = 3; bool flag = true; double f = 0; int i = 0; int j = 0; for(i=5; i&lt;=value; i+=2) &#123; flag = true; f = sqrt(i); for(j=0; j&lt;num;j++) &#123; if(i%numbers[j]==0) &#123; flag = false; break; &#125; if(numbers[j]&gt;f) &#123; break; &#125; &#125; if(flag) &#123; numbers[num] = i; num++; &#125; &#125; free(numbers); RETURN_LONG(num);&#125; PHP 语言本身底层性能引擎提升第三个性能优化层面是语言本身的性能提升，这个就不是我们普通开发者所能做的了。在 PHP 7以前，寄希望于小版本的改进，但是改进幅度不是非常的显著，比如 PHP 5.3 、PHP 5.4、PHP 5.5、PHP 5.5 对同一段代码的性能比较，有一定程度的进步。 PHP 5.3 的版本在上面的例子中已讲过，需要 33s 左右的时间，我们现在来看别的PHP版本。分别运行如下： PHP 5.4 版，相较 5.3 版已经有一定程度的提升。快 6 秒左右。PHP 5.5 版在 PHP 5.4的基础上又进了一步，快了 6S。PHP5.6 反而有些退步。PHP 7 果真是效率提升惊人，是 PHP5.3 的 3 倍以上。以上是求素数脚本在各个 PHP 版本之间的运行速度区别，尽管只测试了这一个程序，也不是特别的严谨，但是这是在同一台机器上，而且编译 configure 参数也基本一样，还是有一定可比性的。 在宏观层面，除了上面的这些之外，在实际的部署过程中，对 PHP 性能的优化，还体现为要减少在运行中所消耗的资源。所以 FastCGI 模式和 mod_php 的模式比传统的 CGI 模式也更为受欢迎。因为在传统的 CGI 模式中，在每一次脚本运行都需要加载所有的模块。而在程序运行完成了之后，也要释放模块资源。如下图所示：而在 FastCGI 和 mod_php 模式中，则不需要如此。只有 php-fpm 或者 Apache 启动的时候，需要加载一次所有的模块，在具体的某次运行过程中，并不需要再次加载和释放相关的模块资源。这样程序性能的效率得到了提升。以上就是有关 PHP 宏观层面的性能优化的分析，在本文的第二部分我们将探讨应用方面的 PHP 优化准则。敬请期待！","categories":[{"name":"php","slug":"php","permalink":"http://zeco.oschina.io/categories/php/"},{"name":"底层","slug":"php/底层","permalink":"http://zeco.oschina.io/categories/php/底层/"}],"tags":[{"name":"php","slug":"php","permalink":"http://zeco.oschina.io/tagcloud/php/"},{"name":"底层性能","slug":"底层性能","permalink":"http://zeco.oschina.io/tagcloud/底层性能/"}]},{"title":"php+salt第二弹","slug":"php+salt_2","date":"un55fin55","updated":"un55fin55","comments":true,"path":"2016/09/16/php+salt_2/","link":"","permalink":"http://zeco.oschina.io/2016/09/16/php+salt_2/","excerpt":"之前说过加salt和MD5结合加密，当然加密方式不可能仅仅MD5这单一的加密算法，这里是一些更加详细的整理。 SHA256 和 SHA512其实跟前面的MD5同期的还有一个SHA1加密方式的，不过也是算法比较简单，所以这里就一笔带过吧。而这里即将要说到的SHA256 和 SHA512都是来自于SHA2家族的加密函数，看名字可能你就猜的出来了，这两个加密方式分别生成256和512比特长度的hash字串。 他们的使用方法如下： 12&lt;?php $password = hash(&quot;sha256&quot;, $password);","text":"之前说过加salt和MD5结合加密，当然加密方式不可能仅仅MD5这单一的加密算法，这里是一些更加详细的整理。 SHA256 和 SHA512其实跟前面的MD5同期的还有一个SHA1加密方式的，不过也是算法比较简单，所以这里就一笔带过吧。而这里即将要说到的SHA256 和 SHA512都是来自于SHA2家族的加密函数，看名字可能你就猜的出来了，这两个加密方式分别生成256和512比特长度的hash字串。 他们的使用方法如下： 12&lt;?php $password = hash(&quot;sha256&quot;, $password); PHP内置了hash()函数，你只需要将加密方式传给hash()函数就好了。你可以直接指明sha256, sha512, md5, sha1等加密方式。 Salt盐在加密的过程，我们还有一个非常常见的小伙伴：盐值。对，我们在加密的时候其实会给加密的字符串添加一个额外的字符串，以达到提高一定安全的目的： 123456&lt;?phpfunction generateHashWithSalt($password) &#123; $intermediateSalt = md5(uniqid(rand(), true)); $salt = substr($intermediateSalt, 0, 6); return hash(&quot;sha256&quot;, $password . $salt);&#125; Bcrypt如果让我来建议一种加密方式的话，Bcrypt可能是我给你推荐的最低要求了，因为我会强烈推荐你后面会说到的Hashing API，不过Bcrypt也不失为一种比较不错的加密方式了。 1234567&lt;?phpfunction generateHash($password) &#123; if (defined(&quot;CRYPT_BLOWFISH&quot;) &amp;&amp; CRYPT_BLOWFISH) &#123; $salt = &apos;$2y$11$&apos; . substr(md5(uniqid(rand(), true)), 0, 22); return crypt($password, $salt); &#125;&#125; Bcrypt 其实就是Blowfish和crypt()函数的结合，我们这里通过CRYPT_BLOWFISH判断Blowfish是否可用，然后像上面一样生成一个盐值，不过这里需要注意的是，crypt()的盐值必须以$2a$或者$2y$开头，详细资料可以参考下面的链接：crypt_blowfish更多资料可以看这里：crypt ★Password Hashing API这里才是我们的重头戏，Password Hashing API是PHP 5.5之后才有的新特性，它主要是提供下面几个函数供我们使用： 1234password_hash() – 对密码加密.password_verify() – 验证已经加密的密码，检验其hash字串是否一致.password_needs_rehash() – 给密码重新加密.password_get_info() – 返回加密算法的名称和一些相关信息. 虽然说crypt()函数在使用上已足够，但是password_hash()不仅可以使我们的代码更加简短，而且还在安全方面给了我们更好的保障，所以，现在PHP的官方都是推荐这种方式来加密用户的密码，很多流行的框架比如Laravel就是用的这种加密方式。 12&lt;?php$hash = password_hash($passwod, PASSWORD_DEFAULT); 对，就是这么简单，一行代码，All done。 PASSWORD_DEFAULT目前使用的就是Bcrypt，所以在上面我会说推荐这个，不过因为Password Hashing API做得更好了，我必须郑重地想你推荐Password Hashing API。这里需要注意的是，如果你代码使用的都是PASSWORD_DEFAULT加密方式，那么在数据库的表中，password字段就得设置超过60个字符长度，你也可以使用PASSWORD_BCRYPT，这个时候，加密后字串总是60个字符长度。 这里使用password_hash()你完全可以不提供盐值(salt)和 消耗值 (cost)，你可以将后者理解为一种性能的消耗值，cost越大，加密算法越复杂，消耗的内存也就越大。当然，如果你需要指定对应的盐值和消耗值，你可以这样写： 123456&lt;?php$options = [ &apos;salt&apos; =&gt; custom_function_for_salt(), //write your own code to generate a suitable salt &apos;cost&apos; =&gt; 12 // the default cost is 10];$hash = password_hash($password, PASSWORD_DEFAULT, $options); 密码加密过后，我们需要对密码进行验证，以此来判断用户输入的密码是否正确： 1234567&lt;?phpif (password_verify($password, $hash)) &#123; // Pass&#125;else &#123; // Invalid&#125; 很简单的吧，直接使用password_verify就可以对我们之前加密过的字符串（存在数据库中）进行验证了。 然而，如果有时候我们需要更改我们的加密方式，如某一天我们突然想更换一下盐值或者提高一下消耗值，我们这时候就要使用到password_needs_rehash()函数了： 1234567&lt;?phpif (password_needs_rehash($hash, PASSWORD_DEFAULT, [&apos;cost&apos; =&gt; 12])) &#123; // cost change to 12 $hash = password_hash($password, PASSWORD_DEFAULT, [&apos;cost&apos; =&gt; 12]); // don&apos;t forget to store the new hash!&#125; 只有这样，PHP的Password Hashing API才会知道我们重现更换了加密方式，这样的主要目的就是为了后面的密码验证。 简单地说一下password_get_info()，这个函数一般可以看到下面三个信息： 123algo – 算法实例algoName – 算法名字options – 加密时候的可选参数 本文到此结束，那么…go! 参考：laravist","categories":[{"name":"安全","slug":"安全","permalink":"http://zeco.oschina.io/categories/安全/"}],"tags":[{"name":"php","slug":"php","permalink":"http://zeco.oschina.io/tagcloud/php/"},{"name":"verify","slug":"verify","permalink":"http://zeco.oschina.io/tagcloud/verify/"},{"name":"hash api","slug":"hash-api","permalink":"http://zeco.oschina.io/tagcloud/hash-api/"}]},{"title":"swoole的进程模型架构[转]","slug":"swoole_1","date":"un66fin66","updated":"un44fin44","comments":true,"path":"2016/08/13/swoole_1/","link":"","permalink":"http://zeco.oschina.io/2016/08/13/swoole_1/","excerpt":"原文出处：Rango 韩天峰 swoole的强大之处就在与其进程模型的设计，既解决了异步问题，又解决了并行。","text":"原文出处：Rango 韩天峰 swoole的强大之处就在与其进程模型的设计，既解决了异步问题，又解决了并行。 主线程MainReactorswoole启动后主线程会负责监听server socket，如果有新的连接accept，主线程会评估每个Reactor线程的连接数量。将此连接分配给连接数最少的reactor线程。这样的好处是 每个reactor线程持有的连接数是非常均衡的，没有单个线程负载过高的问题 解决了惊群问题，尤其是拥有多个listen socket时，节约了线程唤醒和切换的开销 主线程内还接管了所有信号signal的处理，使Reactor线程运行中可以不被信号打断。 管理进程Managerswoole运行中会创建一个单独的管理进程，所有的worker进程和task进程都是从管理进程Fork出来的。管理进程会监视所有子进程的退出事件，当worker进程发生致命错误或者运行生命周期结束时，管理进程会回收此进程，并创建新的进程。 管理进程还可以平滑地重启所有worker进程，以实现程序代码的重新加载。 异步Reactor线程swoole拥有多线程Reactor，所以可以充分利用多核，开启CPU亲和设置后，Reactor线程还可以绑定单独的核，节约CPU Cache开销。 swoole的Reactor线程是全异步非阻塞的，即使你的worker进程用了同步模式，依然不影响reactor线程的性能。在worker进程组很繁忙的状况下，reactor线程完全不受影响，依然可以收发处理数据。 TCP是流式的，没有边界，所以处理起来很麻烦。Reactor线程可以根据EOF或者包头长度，自动缓存数据，组装数据包。等一个请求完全收到后，再投递给Worker进程。 同步或异步Worker进程与传统的半同步半异步服务器不同，Swoole的worker进程可以是同步的也可以异步的，这样带来了最大的灵活性。当你的Server需要很高性能，业务逻辑较为简单时你可以选择异步模式。当业务逻辑复杂多变，可以选择同步模式。 这里要比Node.js强大太多了。 TaskWorker进程池swoole除了Reactor线程，Worker进程外还提供了TaskWorker进程池，目的是为了解决在业务代码中，有些逻辑部分不需要马上执行。利用task进程池，可以方便的投递一个异步任务去执行，在Worker进程空闲时再去捕获任务执行的结果。","categories":[{"name":"php","slug":"php","permalink":"http://zeco.oschina.io/categories/php/"},{"name":"swoole","slug":"php/swoole","permalink":"http://zeco.oschina.io/categories/php/swoole/"}],"tags":[{"name":"php","slug":"php","permalink":"http://zeco.oschina.io/tagcloud/php/"},{"name":"swoole","slug":"swoole","permalink":"http://zeco.oschina.io/tagcloud/swoole/"},{"name":"网络通信","slug":"网络通信","permalink":"http://zeco.oschina.io/tagcloud/网络通信/"}]},{"title":"分布式服务器集群架构方案思考","slug":"zfenbu_1","date":"un55fin55","updated":"un66fin66","comments":true,"path":"2016/07/15/zfenbu_1/","link":"","permalink":"http://zeco.oschina.io/2016/07/15/zfenbu_1/","excerpt":"网上看到一个分布式的服务器集群架构，看了下觉得自己对于分布式的理解清晰了不少，于是摘录下来以免丢失。","text":"网上看到一个分布式的服务器集群架构，看了下觉得自己对于分布式的理解清晰了不少，于是摘录下来以免丢失。原文出处：分布式服务器集群架构方案思考 by 夏日小草 大型网站演化简单说，分布式是以缩短单个任务的执行时间来提升效率的，而集群则是通过提高单位时间内执行的任务数来提升效率。 集群主要分为：高可用集群(High Availability Cluster)，负载均衡集群(Load Balance Cluster，nginx即可实现)，科学计算集群(High Performance Computing Cluster)。 分布式是指将不同的业务分布在不同的地方；而集群指的是将几台服务器集中在一起，实现同一业务。分布式中的每一个节点，都可以做集群。 而集群并不一定就是分布式的。 之前在网上看到一篇关于大型网站演化的博客。page 每个大型网站都会有不同的架构模式，而架构内容也就是在处理均衡负载，缓存，数据库，文件系统等，只是在不同的环境下，不同的条件下，架构的模型不一样，目的旨在提高网站的性能。 最初的架构只有应用程序，数据库，文件服务。到后来，分布式服务、集群架设。 关于均衡负载方案在上一篇，《Nginx反向代理实现均衡负载》讨论过过的nginx现实均衡负载方案，这里选择另一种HAProxy+Keepalived双机高可用均衡负载方案。 HAProxy是免费、极速且可靠的用于为TCP和基于HTTP应用程序提供高可用、负载均衡和代理服务的解决方案，尤其适用于高负载且需要持久连接或7层处理机制的web站点。 不论是Haproxy还是Keepalived甚至是上游服务器均提高生产力并增强可用性,也就是如下架构中Haproxy,Keepalived,Httpd服务器任意宕机一台服务还是可以正常运行的。 HAProxy的优点： 1、HAProxy是支持虚拟主机的，可以工作在4、7层(支持多网段)； 2、能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作； 3、支持url检测后端的服务器； 4、本身仅仅就只是一款负载均衡软件；单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的； 5、HAProxy可以对Mysql读进行负载均衡，对后端的MySQL节点进行检测和负载均衡； 关于Redis缓存方案缓存分为服务器缓存和应用程序缓存。 关于应用程序内缓存，已经在Jue后台框架里面做了模块处理了。 关于服务器缓存，主要缓存服务器文件，减少服务器和php交互，减少均衡负载服务器和应用程序服务器交互。 缓存里面有一种典型的memcached，现在用的多的是redis轻量级缓存方案。 关于memcached与redis，看这篇 《Memcached vs Redis?》 Redis主要将数据存储在各种格式：列表，数组，集合和排序集，一次能接受多个命令，阻塞读写，等待直到另一个进程将数据写入高速缓存。一篇关于Reids缓存方案。《高可用、开源的Redis缓存集群方案》 关于NoSQL快速存储方案NoSQL在这里的使用价值是处理一些琐事，比如用户个人网站的一些css值，height,width,color等等的小而繁多的数据，采用NoSQL旨在提升数据库速度，减少对MySQL的SELECT请求。 关于NoSQL的方案很多了，选一个简单的MongDB好了。 关于分布式MySQL方案(做分布式MySQL还没尝试过，初期也不清楚mysql所需要的压力，所以第一期不打算做分布式MySQL) 《标准MySQL数据库外的5个开源兼容方案》 分布式集群方案综合起来，大致就是如下模型，初探分布式架构，还有很多要修改的，待续，时时更新中… 观后所感一个完整的架构设计并不是一件简单的事，其中涉及的知识很多，我也心知一口气吃不成胖子，更多的问题留待自己有更加成熟的思考和理解之后，再来整理","categories":[{"name":"分布式部署","slug":"分布式部署","permalink":"http://zeco.oschina.io/categories/分布式部署/"}],"tags":[{"name":"拿来的东西","slug":"拿来的东西","permalink":"http://zeco.oschina.io/tagcloud/拿来的东西/"},{"name":"分布式","slug":"分布式","permalink":"http://zeco.oschina.io/tagcloud/分布式/"}]},{"title":"四种基本的排序算法学习总结","slug":"algorithm_1","date":"un44fin44","updated":"un55fin55","comments":true,"path":"2016/06/23/algorithm_1/","link":"","permalink":"http://zeco.oschina.io/2016/06/23/algorithm_1/","excerpt":"都说算法是程序的核心,但是作为一个半路出家的程序员，情不自禁的有点畏惧这个东西，但是今天却被教训了一顿，因为亲眼目睹前辈以一个简单的排序方法提升了好几倍的查询速度，好吧，决心一点点的啃下算法的硬骨头，提升一点自己coding的视野和高度。","text":"都说算法是程序的核心,但是作为一个半路出家的程序员，情不自禁的有点畏惧这个东西，但是今天却被教训了一顿，因为亲眼目睹前辈以一个简单的排序方法提升了好几倍的查询速度，好吧，决心一点点的啃下算法的硬骨头，提升一点自己coding的视野和高度。 今天就整理一下最简单的四个排序算法：冒泡、快速、选择、插入。快速排序对一个乱序的数组，每次选择一个指定位置的元素（一般是第一个），每次scan，将被选择的元素作为基准，将乱序的数组分为大小两部分，后续递归剩下的部分，直到分割出来的数组长度不可再分。具体举例如下12345678910111213141516171819202122function quick_sort($arr) &#123; $length = count($arr); if($length &lt;= 1) &#123; //递归出口 return $arr; &#125; $base_array = $arr[0]; //选择第一个元素作为基准 //初始化两个数组,保证每次递归签数组清空 $left_array = array(); //小于基准的 $right_array = array(); //大于基准的 for($i=1; $i&lt;$length; $i++) &#123; if($base_num &gt; $arr[$i]) &#123;//放入左边数组 $left_array[] = $arr[$i]; &#125; else &#123; //放入右边 $right_array[] = $arr[$i]; &#125; &#125; //递归排序 $left_array = quick_sort($left_array); $right_array = quick_sort($right_array); //合并数组 return array_merge($left_array, array($base_num), $right_array); &#125; 冒泡排序冒泡排序基本是一个programer要学习的第一个算法，但是简单不代表他真的就low，就像递归和迭代算法一样，并没有那个算法是最优的，而是适当的环境下选择适当的算法。冒泡算法，通过两层循环，从第一个元素开始，每次对比相邻的元素，依据他们的大小和需要的排序决定他们的位置，最后获得一个重新排序过的数组。具体举例如下12345678910111213function bubbleSort($arr)&#123; $len=count($arr); for($i=1;$i&lt;$len;$i++) &#123; //第一层循环控制层数 for($k=0;$k&lt;$len-$i;$k++)&#123; //第二层循环用来控制级数 if($arr[$k]&gt;$arr[$k+1])&#123; $tmp=$arr[$k+1]; $arr[$k+1]=$arr[$k]; $arr[$k]=$tmp; &#125; &#125; &#125; return $arr; &#125; 选择排序选择排序是通过假设一个假值，然后获得这个假值的位置（每次选择最大或者最小的树），寻找到他的位置，排列出一个固定顺序的数组。具体举例如下12345678910111213141516171819202122function selectSort($arr) &#123; //双重循环完成，外层控制轮数，内层控制比较次数 $len=count($arr); for($i=0; $i&lt;$len-1; $i++) &#123; //假设最小的值的位置 $p = $i; for($j=$i+1; $j&lt;$len; $j++) &#123; //比较，发现更小的,记录下最小值的位置；并且在下次比较时采用已知的最小值进行比较。 if($arr[$p] &gt; $arr[$j]) &#123; $p = $j; &#125; &#125; //已经确定了当前的最小值的位置，保存到$p中。如果发现最小值的位置与当前假设的位置$i不同，则位置互换即可。 if($p != $i) &#123; $tmp = $arr[$p]; $arr[$p] = $arr[$i]; $arr[$i] = $tmp; &#125; &#125; //返回最终结果 return $arr; &#125; 插入排序假设一个数组是有序的，现在要把第n个数插到前面的有序数中，使得这n个数也是排好顺序的。如此反复循环，直到全部排好顺序。具体举例如下123456789101112131415161718function insertSort($arr) &#123; $len=count($arr); for($i=1, $i&lt;$len; $i++) &#123; $tmp = $arr[$i]; //内层循环控制，比较并插入 for($j=$i-1;$j&gt;=0;$j--) &#123; if($tmp &lt; $arr[$j]) &#123; //发现插入的元素要小，交换位置，将后边的元素与前面的元素互换 $arr[$j+1] = $arr[$j]; $arr[$j] = $tmp; &#125; else &#123; //如果碰到不需要移动的元素，由于是已经排序好是数组，则前面的就不需要再次比较了。 break; &#125; &#125; &#125; return $arr; &#125;","categories":[{"name":"算法学习","slug":"算法学习","permalink":"http://zeco.oschina.io/categories/算法学习/"}],"tags":[{"name":"排序","slug":"排序","permalink":"http://zeco.oschina.io/tagcloud/排序/"},{"name":"Algorithm","slug":"Algorithm","permalink":"http://zeco.oschina.io/tagcloud/Algorithm/"}]},{"title":"git操作(I) 提交到远程仓库","slug":"git_1","date":"un55fin55","updated":"un22fin22","comments":true,"path":"2016/05/27/git_1/","link":"","permalink":"http://zeco.oschina.io/2016/05/27/git_1/","excerpt":"目前市面有许多第三方git操作软件，比如我曾经用过的Source Tree，就是一款上手和使用起来都不错的工具，但时间一长，总觉得差点微妙的feel，于是又灰溜溜的决定把命令行捡回来，写个系列的使用记录。","text":"目前市面有许多第三方git操作软件，比如我曾经用过的Source Tree，就是一款上手和使用起来都不错的工具，但时间一长，总觉得差点微妙的feel，于是又灰溜溜的决定把命令行捡回来，写个系列的使用记录。 创建一个本地仓库 现在，有一个尚未开始的项目，那么进入你项目存放的目录12$ cd XXX$ git init 这样你就获得了一个仓库，并且处于当前master branch上 或者通过clone一个远程的仓库到本地12$ cd XXX$ git clone url:repositories [repo&apos;s name] 需要注意的是，这个本地文件夹（XXX）要是一个空的文件夹，否则会报错 完成文件提交 创建一个本地文件1$ vim ./hello_git.md 在文件输入你想加入的内容1~ hello git :) 保存后退出 添加文件到暂存区，提交文件123456789使用$ git status查看当前文件状态，出现未添加文件，使用$ git add ./hello_git.md再查看文件状态‘$ git status这里显示文件暂存，然后准备commit$ git commit -m &apos;备注信息&apos;再次查看工作区时，显示tree clean，说明提交成功 你也可以使用 git status -s 命令查看更为详细的状态也可以通过 git log 来查看每次commit 关联远程仓库git 属于分布式版本控制系统,每个电脑就相当于一个仓库，但如果你有一个geek的心，你可以将你的代码分享到一个远程的托管系统上，其中的代表有世界上最大的同性交友网站github，还有国内的两个不错的托管平台coding和码云。 我们可以通过remote命令将自己的代码托管在远程的代码托管平台上 查看关联的远程仓库1$ git remote -v 获得已经关联的远程仓库2 . 配置本地账户信息配置一个本地的用户信息，使得仓库中的操作是由谁做出的12$ git config --global user.name &quot;your_username&quot; $ git config --global user.email your_email@domain.com 生成ssh秘钥1$ ssh-keygen -t rsa -C &quot;your_email@domain.com&quot; 输入命令之后会提示三次确认，一直回车确定，最后提示创建成功，然后进入主文件查看生成的id_rsa和id_rsa.pub，将id_rsa.pub公钥打开，添加到远程创建的长裤中 打开公钥使用编辑器，否则可能会影响编码，导致添加失败 添加远程仓库地址12$ git remote add origin https://your_username@bitbucket.org/your_username/name_of_remote_repository.git $ git push origin master 显示push成功之后，就可以再远程仓库里看到你提交的代码了 如果使用的clone仓库，那么本地默认存在远程仓库地址，只需要添加ssh公钥认证之后就可以提交代码到远程仓库了 如果你看了这些还是不太了解提交的过程，可以参考git官方给出的操作book","categories":[{"name":"工具","slug":"工具","permalink":"http://zeco.oschina.io/categories/工具/"},{"name":"git","slug":"工具/git","permalink":"http://zeco.oschina.io/categories/工具/git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://zeco.oschina.io/tagcloud/git/"}]},{"title":"好玩的ReidsCycle","slug":"rediscycle","date":"un11fin11","updated":"un11fin11","comments":true,"path":"2016/05/16/rediscycle/","link":"","permalink":"http://zeco.oschina.io/2016/05/16/rediscycle/","excerpt":"最近，突发奇想的想要设计一个延时触发的项目，上网翻腾了一把，着实发现了不少有意思的东西，这里附上感觉不错的两处：一、二","text":"最近，突发奇想的想要设计一个延时触发的项目，上网翻腾了一把，着实发现了不少有意思的东西，这里附上感觉不错的两处：一、二 比较常见的方案使用cron定时任务，但是cron设定任务最低的精度到minute,某些时候，我们需要的可能是精确到second级别的定时计划。 再者，当表单数据量巨大时，使用cron进行轮询的效率就很低。 因为，每次轮询都要扫一次库，之前执行过的记录仍会被扫描，这样的效率就会下降 使用redis实现高效的延时设计参见一中的设计，这里包含两个重要的数据结构： 环形队列，一个头尾相接数组，其包含3600个slot的环形队列（一环设计为1h==60min==3600s，cycle=n?） work_ task, 置于指定时间点的 [‘set’=&gt;[cycle,dot,work_task]] timer, 一个和环形队列对应的timer是必须的,每当timer变化设定的dot值时，环形队列的指针（index）便移动一位，同事检测当前dot上的set集，对比集中cycle，如果对应上，便执行此点上的work_ task 这里我们设定一个例子： slot(3600,dot=1s) timer=dot=1s set=[task_1=&gt;[‘cycle’=&gt;3,’dot’=&gt;667,’task’=&gt;function(){echo ‘do it’}]] 任务执行的逻辑如下：123(cycle=1,dot=667)--&gt;1 != 3 &amp;&amp; 667 == 667 continue(cycle=2,dot=667)--&gt;2 != 3 &amp;&amp; 667 == 667 continue(cycle=3,dot=667)--&gt;3 == 3 &amp;&amp; 667 == 667 do work_task--&gt;echo do it--&gt;delete work_task 从任务的逻辑不难看出， 每次指针移动时，只需要查看当前dot上是否有set如果有set集则进行判断cycle值，决定是否执行任务，无需轮询全部任务，效率提升 每个订单任务被执行之后，即刻更新任务数据，一个任务只执行一次 时效性自定义，再不影响系统性能的情况下，就能够做到足够高的精确度","categories":[{"name":"数据库","slug":"数据库","permalink":"http://zeco.oschina.io/categories/数据库/"},{"name":"nosql","slug":"数据库/nosql","permalink":"http://zeco.oschina.io/categories/数据库/nosql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://zeco.oschina.io/tagcloud/redis/"},{"name":"环形队列","slug":"环形队列","permalink":"http://zeco.oschina.io/tagcloud/环形队列/"},{"name":"延时设计","slug":"延时设计","permalink":"http://zeco.oschina.io/tagcloud/延时设计/"}]},{"title":"PHP+salt加密","slug":"php+salt","date":"un55fin55","updated":"un55fin55","comments":true,"path":"2016/05/13/php+salt/","link":"","permalink":"http://zeco.oschina.io/2016/05/13/php+salt/","excerpt":"","text":"最近又听闻用户信息泄露的新闻，此前，作为it小白的时候，实在不知道怎么处理这样的变故，而泄漏的信息如果被黑客利用，通过撞库的方法就可破解大多数用户的密码，毕竟用户偏向于使用自己简单容易记住的密码，也不会多去改变他们，这时，如果我们开发人员还使用单一的加密方式，那是十分不明智的。 MD5加盐加密我们对md5()这个函数再是熟悉不过了，都使用过md5()对用户密码进行加密处理，这样做没有错，因为MD5加密不可逆，但是这样做的安全性还是很低的，因为很多网站的用户数据都是用md5进行加密处理的，而且网上也有许多人为整理出来的常用的MD5加密库，而从CSDN当时泄漏出来的用户信息来看，即便是作为与网络打交道的程序员，其中也有许多使用的是简单的密码组合，及其容易被匹配出来，再者，对于黑客而言，其破解密码手段通过撞库，简单的密码组合就大大增大了密码被破解的几率。 直接去开发一个新的算法来加密，从现实的角度是不实际的，那既然从算法的角度无法实现，那么我们就可以从入口的数据下手，将用户的密码添加一些佐料，这样即便是简单的密码，也会因为我们的加密，提升了密码组合的复杂程度，不会那么轻易的被破解，这就是所谓的加salt。 12345678910$salt = get_salt(SALT); //我们通过设置不同的SALT值来获取不同等级的加密$password = &apos;we2134sda&apos;; //用户处获取的明文密码$md5_password = md5(&apos;your_site&apos;.$password.$salt);//最终加密后密码function get_salt（$param） &#123; $salt = &apos;&apos;; for ($i = 0;$i &lt; $param; $i++) &#123; $salt .= chr(mt_rand(13,$param*12+13)); &#125; return $salt;&#125; 这里我们使用md5加随机生成的salt来增强加密后的密码安全性，然后我们记录下salt值，在用户注册的时候和密码一起生成并保存到数据库中，用户登录验证的时候再把密码和盐值一起组合验证，通过这样的手段就可以加强密码的安全性。","categories":[{"name":"安全","slug":"安全","permalink":"http://zeco.oschina.io/categories/安全/"}],"tags":[{"name":"php","slug":"php","permalink":"http://zeco.oschina.io/tagcloud/php/"},{"name":"verify","slug":"verify","permalink":"http://zeco.oschina.io/tagcloud/verify/"},{"name":"md5","slug":"md5","permalink":"http://zeco.oschina.io/tagcloud/md5/"}]},{"title":"用hexo+github搭建一个静态blog","slug":"your blog","date":"un22fin22","updated":"un00fin00","comments":true,"path":"2016/05/03/your blog/","link":"","permalink":"http://zeco.oschina.io/2016/05/03/your blog/","excerpt":"关于怎么搭建blog的教程网上有一堆，挑一个比较详细的附上：如何搭建一个独立博客——简明Github Pages与Hexo教程这里就记录一些个人探过的一些小坑，以做前车之鉴。","text":"关于怎么搭建blog的教程网上有一堆，挑一个比较详细的附上：如何搭建一个独立博客——简明Github Pages与Hexo教程这里就记录一些个人探过的一些小坑，以做前车之鉴。 配置文件使用hexo搭建blog的时候系统默认了一个theme：landscape 我使用的是这个主题：ICARUS 下载之后要在主配置文件 _config.yaml里配置1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: hexo-theme-icarus //你所下载的主题仓库名称 而如果需要调整请在主题文件夹的 _config.yaml里配置 注意两者的位置主配置文件位于hexo文件的根目录中主题配置文件的目录位于hexo-&gt;themes-&gt;(your themes)-&gt;_config.yaml(一般出事文件还有后缀example，将他去掉就好了) 部署到github使用$ hexo d 就可以将生成好的静态文件部署到github上，但部署文件之前需要在主配置文件里配置123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/yourgithubname/yourgithubname.github.io.git branch: master 注意，这里的仓库名称一定要是你的：github用户名.github.io才会被github默认为pages 但需要注意的是，有些时候这样的配置不一定能够成功，因为在hexo3里使用https:// 会影响他的部署这里要将仓库地址repo改成1repo：git@github.com:username/username.github.io.git 如果还是失败，那就要检查SSH key是否添加成功，以及git的设置是否成功 关于MarkDown的书写使用hexo new post [post title],可以生成一篇新的文章，只需要到/source/_post/下就可以找到生成的title.md文件下面是标题文件的书写123456---title: blog标题categories: [一级分类，二级分类...]tags: [标签1,标签2,标签3...]thumbnail: url of image(缩略图的路径)--- 博文正文的书写惨遭markdown语法，markdown语法兼容html的语法，相信对学习过html标签都不是一件难事。这里再提一点，如果需要只显示部分的博文可以使用1&lt;!--more--&gt; 来分割显示和不显示的文章 关于pluginhexo官网上有许多优秀的plugin，我找了一个比较有意思的标签云插件按照readme一步一步配置就可以实现动态的tagcloud了 最后上一切的起源：hexo","categories":[{"name":"blog","slug":"blog","permalink":"http://zeco.oschina.io/categories/blog/"}],"tags":[{"name":"blog","slug":"blog","permalink":"http://zeco.oschina.io/tagcloud/blog/"},{"name":"hexo","slug":"hexo","permalink":"http://zeco.oschina.io/tagcloud/hexo/"},{"name":"github","slug":"github","permalink":"http://zeco.oschina.io/tagcloud/github/"}]},{"title":"MySQL (III) 字段类型选择","slug":"mysql_uh3","date":"un66fin66","updated":"un44fin44","comments":true,"path":"2016/04/30/mysql_uh3/","link":"","permalink":"http://zeco.oschina.io/2016/04/30/mysql_uh3/","excerpt":"字段是组成一张表的最基本单元，但它们却是数据表设计时不得不严密考虑的部分，因为不恰当的字段类型选择，不仅容易造成数据库空间的浪费，以及冗余的产生，且在数据量巨大以及查询频繁的字段或表，将严重影响数据的读写速度。","text":"字段是组成一张表的最基本单元，但它们却是数据表设计时不得不严密考虑的部分，因为不恰当的字段类型选择，不仅容易造成数据库空间的浪费，以及冗余的产生，且在数据量巨大以及查询频繁的字段或表，将严重影响数据的读写速度。 Int（bigint，int，mediumint，smallint，tinyint）因为计算机本身只分辨数字型的数据，所以合理的使用整形字段可以提升数据读取的速度。 整形数据由大至小，从16个字节到1个字节不等，对于不同需求的表选择不同类型的int类型作为表的primary key是一个不错的选择。 这里还要提到的一点，虽然MySQL数据库提供了datetime类型的字段，但我们还是尽量以int类型的格式来存储时间戳的方法来保存时间数据，这样可以提高读取速度和减少I/O的开销。 在一些单选或者多选的字段里，也应当尽量避免使用枚举，适当的选用tinyint这样的短int数据是更好的选择。 Float（float，double，decimal）其实在浮点类型的数据中，decimal并不是作为数字存储在数据库中的，相反他是以我们’厌恶’的字符类型存在。 在这里，我们不得不来讨论一下浮点型数的一些缺点，单/双精度的数据类型在数据库中超过一定位数之后会出现失去精度的的情况，这个位数的大小在6位小数，而我们存储一些类似价格，额度等字段时，需要一种完全精确的记录，而decimal（65，30）如此长度的记录数完全满足我们的需求，这是浮点类型数据我们应当关心的部分。 字符（char，varchar）虽然字符类型的数据在读取时并不佳，但字符型的数据却是一个数据库不可忽略的部分。 char和varchar的不同体现在多个方面 1.char类型数据最大长度（255），而varchar类型数据的最大长度为（65535） 这里需要注意的是，varchar类型的数据长度存储的字节长度，即varchar类型的数据需要考虑编码的原因 2.两者最主要体现在两者侧重的方面不同，char类型数据属于定长数据，不论存储多少长度的数据，都占据一定的空间，而varchar数据则不论在表中设计多大的长度，都依照存储的字符串长度来决定占用的空间 3.因为varchar之所节省空间，是因为varchar经过了一层数据库的算法过滤，恰恰也是这层过滤，使得varchar类型的数据在读写速度上劣于char类型的数据。 总而言之，varchar和char两者，一个为了节省空间而浪费了时间，一个为了节省时间而浪费了空间，这就需要我们在设计表格的时候，谨慎的去考虑和取舍了。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://zeco.oschina.io/categories/数据库/"},{"name":"mysql","slug":"数据库/mysql","permalink":"http://zeco.oschina.io/categories/数据库/mysql/"}],"tags":[{"name":"字段优化","slug":"字段优化","permalink":"http://zeco.oschina.io/tagcloud/字段优化/"}]},{"title":"Mysql (II) 引擎","slug":"mysql_uh2","date":"un44fin44","updated":"un44fin44","comments":true,"path":"2016/04/21/mysql_uh2/","link":"","permalink":"http://zeco.oschina.io/2016/04/21/mysql_uh2/","excerpt":"这里，只简单的讨论两种常见的引擎：MyISAM和InnoDB的区别。","text":"这里，只简单的讨论两种常见的引擎：MyISAM和InnoDB的区别。 a. MyISAM类型不支持事务处理等高级处理，而InnoDB类型支持. b. MyISAM类型的表强调的是性能，其执行数度比InnoDB类型更快. c. InnoDB不支持fulltext类型的索引. d. InnoDB 中不保存表的具体行数，也就是说，执行select count(*) from table时，InnoDB要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可. e. 对于auto_increment类型的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中，可以和其他字段一起建立联合索引。 f. delete from table时，InnoDB不会重新建立表，而是一行一行的删除。 g. load table from master操作对InnoDB是不起作用的，解决方法是首先把InnoDB表改成MyISAM表，导入数据后再改成InnoDB表，但是对于使用的额外的InnoDB特性(例如外键)的表不适用. h. MyISAM支持表锁，InnoDB支持行锁。 B-treeInnoDB的B-tree结构 如上图所示，InnoDB的搜索树由两层结构组成，每次对InnoDB引擎的表操作时，实际上是经过了两次的处理，先通过索引找到主键的位置，再获取对应主键的记录，这样不论是写入还是读取的速度都讲收到影响。 MyISAM的B-tree结构 MyISAM的结构决定了，每次读取和写入的时候不用考虑主键的顺序重排，所以MyISAM引擎的表的读取速度较InnoDB的快","categories":[{"name":"数据库","slug":"数据库","permalink":"http://zeco.oschina.io/categories/数据库/"},{"name":"mysql","slug":"数据库/mysql","permalink":"http://zeco.oschina.io/categories/数据库/mysql/"}],"tags":[{"name":"数据库引擎","slug":"数据库引擎","permalink":"http://zeco.oschina.io/tagcloud/数据库引擎/"}]},{"title":"Mysql (I) 数据表设计规范","slug":"mysql_uh1","date":"un00fin00","updated":"un44fin44","comments":true,"path":"2016/04/03/mysql_uh1/","link":"","permalink":"http://zeco.oschina.io/2016/04/03/mysql_uh1/","excerpt":"三范式&nbsp;&nbsp;&nbsp;&nbsp;俗话说，好的表结构是一个项目成功的一般，而在项目中我们一般按照三范式的规范来设计我们的表格。三范式的具体要求如下： 原子性（不可再分的字段） 非主键字段必须依赖主键 消除非主键之间的传递依赖","text":"三范式&nbsp;&nbsp;&nbsp;&nbsp;俗话说，好的表结构是一个项目成功的一般，而在项目中我们一般按照三范式的规范来设计我们的表格。三范式的具体要求如下： 原子性（不可再分的字段） 非主键字段必须依赖主键 消除非主键之间的传递依赖 &nbsp;&nbsp;&nbsp;&nbsp;当然，三范式在网上存在许多不同的版本，但不论是哪个版本的三范式，其中心思想都是一样的，那就是设计出比较合理的数据表，尽可能的减少代码的冗余。 但需要注意的是，代码的冗余只能减少，而不是消灭 具体设计思路如下： id name order order_name address weather price (非设计规范表) (拆分address字段保证设计表的原子性) -&gt; id name order order_name country province city weather price (将非主键依赖的weather的字段拆分出去) -&gt; id name order order_name country province city price (消除order和order_name之间的传递依赖，将非主键之间的传递依赖消除) -&gt; id name order country province city price 逆范式&nbsp;&nbsp;&nbsp;&nbsp;实际项目中，并不是完全按三范式的规范来设计表的结构，具体的项目中，逆范式的设计有时候可以简化sql的语句，提高sql语句的执行效率，此时逆范式的设计明显更有利于我们的项目，这个情况下使用逆范式的设计将更为科学。 例如，我们现在有两张表，一张分类表（category），一张商品表（goods），这里我们项目需要查询分类id、分类名称、商品数量三个字段，具体的sql语句如下：1select c.*,count(g.goods_id) goods_num from category as c left join goods as g on c.cat_id = g.cat_id group by c.cat_id; 可以看到，这个使用jion连表查询的sql语句相对于简单的表结构并不简单，而如果我们给分类表加上一个对应的商品数量字段，这样的sql语句将大大简化，这个时候我们大可不必严守三范式的设计思路，不妨使用逆范式的方式来设计这张表。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://zeco.oschina.io/categories/数据库/"},{"name":"mysql","slug":"数据库/mysql","permalink":"http://zeco.oschina.io/categories/数据库/mysql/"}],"tags":[{"name":"表设计","slug":"表设计","permalink":"http://zeco.oschina.io/tagcloud/表设计/"}]}]}